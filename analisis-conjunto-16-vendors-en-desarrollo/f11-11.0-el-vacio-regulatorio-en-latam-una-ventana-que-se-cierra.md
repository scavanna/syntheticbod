---
icon: check
---

# F11 - 11.0 EL VAC√çO REGULATORIO EN LATAM: UNA VENTANA QUE SE CIERRA

**¬ß11.0 El Vac√≠o Regulatorio en LATAM** ‚Äî Tabla de los cinco vectores regulatorios (marcos nacionales, EU AI Act extraterritorial, reforma Ley 25.326, regulaci√≥n sectorial BCRA/CNV, presi√≥n del mercado) mostrando la evoluci√≥n de 2020-2023 al estado actual 2026. Dato clave CEPAL/CENIA ILIA 2025: LATAM es el 14% de visitas globales a soluciones de IA pero la capacidad regulatoria sigue rezagada.

**¬ß11.1 Mapa Regulatorio LATAM 2026: Estado por Pa√≠s** ‚Äî An√°lisis detallado de cada jurisdicci√≥n con clasificaci√≥n Pioneer / Adopter / Explorer:

* **Brasil (Pioneer):** LGPD vigente desde 2020. PL 2338/2023 aprobado por el Senado en diciembre de 2024, en revisi√≥n de la C√°mara con Comisi√≥n Especial de 33 miembros desde abril 2025. Multas hasta BRL 50M o 2% de facturaci√≥n. ANPD como autoridad supervisora. Sandboxes regulatorios para fintech, healthtech y smart cities activos hasta diciembre 2026.
* **Chile (Pioneer):** Proyecto de ley de IA aprobado por la C√°mara de Diputados el 13 de octubre de 2025, actualmente en el Senado. Ley Marco de Ciberseguridad 21.663 ya vigente ‚Äî crea la ANCI con poderes de supervisi√≥n sobre sistemas de IA en infraestructura cr√≠tica. Nueva Ley de Datos con Agencia de Protecci√≥n de Datos operacional en 2026.
* **Colombia, M√©xico, Per√∫, Uruguay, Panam√°, Ecuador** ‚Äî Estado legislativo y nivel de impacto para operaciones argentinas.

**¬ß11.2 EU AI Act Extraterritorial** ‚Äî Seis escenarios concretos para determinar si aplica a una organizaci√≥n argentina (proveedor de software a la UE, procesadora de datos de europeos, filial de empresa europea, cadena de suministro B2B, sin exposici√≥n UE, caso espec√≠fico Microsoft Argentina). Calendario de deadlines: pr√°cticas prohibidas vigentes desde febrero 2025, sistemas de alto riesgo en agosto 2026 ‚Äî a menos de 6 meses del corte de este informe.

**¬ß11.3 Argentina en Detalle** ‚Äî Dos capas: (1) Ley 25.326 vigente con 7 principios y sus implicancias espec√≠ficas para sistemas de IA (consentimiento, datos sensibles, derecho a impugnar decisiones automatizadas, registro ante AAIP, transferencia internacional); (2) Reforma propuesta 2025 con 7 novedades cr√≠ticas (accountability proactiva, portabilidad, oposici√≥n a decisiones automatizadas, sandbox, datos biom√©tricos como sensibles, EIMPD, plazo de adecuaci√≥n de solo 6 meses); (3) Proyecto S-0071/2025: clasificaci√≥n de 4 niveles de riesgo, Registro Nacional de Sistemas de IA.

**¬ß11.4 An√°lisis de Brechas** ‚Äî Compliance matrix en 4 dimensiones (Gobernanza y Documentaci√≥n, Derechos de los Titulares, Seguridad T√©cnica y Operacional, Transferencia Internacional) con estado ‚úÖ / ‚ö†Ô∏è / ‚ùå para Ley 25.326 vigente, Reforma ARG 2025 y EU AI Act, m√°s la acci√≥n prioritaria para cada brecha. Incluye tabla completa de transferencia internacional con el caso espec√≠fico de DeepSeek (BLOQUEADO por incompatibilidad con Ley 25.326 y GDPR).

**¬ß11.5 Estrategia de Compliance: 12 Meses** ‚Äî 18 acciones distribuidas en 4 trimestres, con el marco regulatorio espec√≠fico que justifica cada acci√≥n y el output esperado: Trimestre 1 (inventario, clasificaci√≥n de riesgo, auditor√≠a de contratos, registro AAIP, evaluaci√≥n de exposici√≥n EU); Trimestre 2 (EIMPDs, revisi√≥n humana de decisiones automatizadas, logs inmutables, bias testing, AI Usage Policy); Trimestre 3 (documentaci√≥n EU AI Act Art. 11 para sistemas de alto riesgo, monitoreo post-deployment, registro EU si aplica, tabletop de inspecci√≥n regulatoria); Trimestre 4 (ISO 42001, scorecard actualizado, monitoreo legislativo, business case de certificaci√≥n).

## 11.0 EL VAC√çO REGULATORIO EN LATAM: UNA VENTANA QUE SE CIERRA

<br>

Las Fases 1 a 10 de este informe construyeron el marco completo de due diligence para IA enterprise, cubriendo los grandes bloques regulatorios globales ‚Äî EU AI Act, GDPR, HIPAA, FedRAMP, DORA, SOC 2. Sin embargo, existe un vac√≠o que el CISO que opera en Argentina no puede permitirse ignorar: el paisaje regulatorio propio de Am√©rica Latina, que en 2025-2026 est√° en una transformaci√≥n sin precedentes.

A diferencia de 2020-2023, cuando LATAM era un espacio de principios voluntarios y estrategias nacionales no vinculantes, en 2026 la regi√≥n tiene tres vectores regulatorios convergentes que crean obligaciones reales: (1) los marcos nacionales emergentes ‚ÄîBrasil con PL 2338/2023, Chile con su proyecto aprobado por la C√°mara de Diputados‚Äî, (2) el impacto extraterritorial del EU AI Act para organizaciones con exposici√≥n a datos europeos o contratos con empresas europeas, y (3) la reforma inminente del marco de protecci√≥n de datos argentino ‚ÄîLey 25.326‚Äî con proyectos activos en el Congreso Nacional.

<br>

| VECTOR REGULATORIO                             | 2020-2023                                           | 2024-2025                                                                                            | 2026 ‚Üí                                                                                                                    |
| ---------------------------------------------- | --------------------------------------------------- | ---------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- |
| Marcos nacionales LATAM                        | Principios voluntarios, estrategias sin enforcement | Brasil aprueba PL 2338/2023 en el Senado. Chile avanza proyecto de ley. 109 iniciativas en 8 pa√≠ses. | Brasil: en revisi√≥n de la C√°mara ‚Äî sanci√≥n esperada 2026. Chile: en el Senado. Argentina: proyecto S-0071/2025 activo.    |
| EU AI Act extraterritorial                     | No vigente                                          | Publicado (Reg. UE 2024/1689). Vigencia agosto 2024. Pr√°cticas prohibidas: febrero 2025.             | Sistemas de alto riesgo: agosto 2026. Deadline cr√≠tico. Plena aplicaci√≥n supervisi√≥n post-market.                         |
| Reforma Ley 25.326 Argentina                   | Marco de a√±o 2000 sin actualizaci√≥n mayor           | Proyectos AAIP pierden estado parlamentario 2024. Nuevos proyectos en 2025.                          | Dos proyectos activos (Carro/Do√±ate 2025). Proyecto IA S-0071/2025 en el Senado. Ventana de 6-12 meses.                   |
| Regulaci√≥n sectorial BCRA/CNV                  | Circulares de protecci√≥n de datos existentes        | Comunicaciones BCRA sobre ciberseguridad para entidades financieras. Sin norma espec√≠fica de IA.     | Expectativa de normas sectoriales de IA para sector financiero en LATAM. BCRA monitoreando desarrollos regionales.        |
| Presi√≥n del mercado (clientes/socios globales) | Cl√°usulas de privacidad est√°ndar                    | DPAs requeridos por socios europeos. Cuestionarios de seguridad cada vez m√°s complejos.              | EU AI Act compliance como requisito de cadena de suministro. ISO 42001 como est√°ndar de facto en licitaciones enterprise. |

<br>

üåé Dato CEPAL/CENIA ILIA 2025: Am√©rica Latina representa el 14% de las visitas globales a soluciones de IA y ocupa el 3er lugar mundial en descargas de aplicaciones de IA generativa. La adopci√≥n supera la capacidad regulatoria ‚Äî y esa brecha es exactamente el riesgo que este an√°lisis aborda para el CISO en Argentina.

<br>

## 11.1 MAPA REGULATORIO LATAM 2026: ESTADO POR PA√çS

<br>

Clasificaci√≥n de madurez regulatoria: Pioneer (marco avanzado con enforcement), Adopter (marco en proceso legislativo activo), Explorer (principios y estrategias, sin ley vinculante). Fuente: CEPAL/CENIA ILIA 2025, an√°lisis White & Case 2024, Niubox 2025.

<br>

### üáßüá∑  BRASIL ‚Äî Pioneer | Marco M√°s Avanzado de la Regi√≥n

| DIMENSI√ìN                              | DETALLE                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| -------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Marco vigente                          | LGPD (Lei Geral de Prote√ß√£o de Dados, No. 13.709/2018): vigente desde septiembre 2020. Es la base legal para el procesamiento de datos personales, incluidos los de sistemas de IA. Autoridad de aplicaci√≥n: ANPD (Autoridade Nacional de Prote√ß√£o de Dados). Multas: hasta 2% de la facturaci√≥n en Brasil o BRL 50 millones por infracci√≥n. La LGPD reconoce el derecho a revisi√≥n humana de decisiones automatizadas que afecten al individuo.                                                                                                                                                                                                                        |
| PL 2338/2023 (AI Act brasile√±o)        | El Senado Federal aprob√≥ el proyecto el 10 de diciembre de 2024. Fue remitido a la C√°mara de Diputados el 17 de marzo de 2025. El 4 de abril de 2025, el presidente de la C√°mara constituy√≥ una Comisi√≥n Especial de 33 miembros para revisar el proyecto. Sanci√≥n esperada: 2025-2026 con posibles enmiendas. Enfoque riesgo-based, alineado con EU AI Act: sistemas de riesgo excesivo (prohibidos), alto riesgo (obligaciones adicionales), bajo riesgo (requisitos m√≠nimos). Multas: hasta BRL 50 millones (\~USD 9M) o 2% de facturaci√≥n. ANPD asumir√° rol de autoridad supervisora. Sandboxes regulatorios para innovaci√≥n en fintech, healthtech y smart cities. |
| Impacto para operaciones en/con Brasil | Organizaciones con presencia en Brasil o que procesen datos de ciudadanos brasile√±os ya est√°n bajo LGPD. Con PL 2338/2023 aprobado, deber√°n: (1) clasificar todos sus sistemas de IA por nivel de riesgo, (2) implementar evaluaciones de impacto (DPIA) para sistemas de alto riesgo, (3) establecer supervisi√≥n humana en decisiones automatizadas de alto impacto, (4) cooperar con la ANPD en auditor√≠as.                                                                                                                                                                                                                                                           |
| Timeline cr√≠tico                       | Sanci√≥n del PL 2338/2023: estimado 2026. Entrada en vigor: plazo de adaptaci√≥n de 2 a√±os propuesto en la ley ‚Äî posible vigencia plena: 2027-2028. Sandbox regulatorio piloto: activo hasta diciembre 2026.                                                                                                                                                                                                                                                                                                                                                                                                                                                              |

<br>

### üá®üá±  CHILE ‚Äî Pioneer | Liderazgo Regional en IA y Ciberseguridad

| DIMENSI√ìN                                 | DETALLE                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| ----------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Proyecto de ley IA                        | El proyecto general de regulaci√≥n de sistemas de IA fue aprobado por la C√°mara de Diputados el 13 de octubre de 2025 y remitido al Senado para segunda revisi√≥n constitucional. Se encuentra actualmente en debate en el Senado. No hay fecha fija de promulgaci√≥n. Enfoque riesgo-based inspirado en EU AI Act y principios OCDE. Categor√≠as: riesgo inaceptable (prohibido), alto riesgo (obligaciones reforzadas), riesgo limitado y sin riesgo evidente. Obligaciones para sistemas de alto riesgo: transparencia, auditabilidad, supervisi√≥n humana, evaluaciones de impacto. |
| Ley Marco de Ciberseguridad No. 21.663    | Vigente desde 2024. Establece obligaciones de ciberseguridad para organismos p√∫blicos y entidades privadas que prestan servicios esenciales o cr√≠ticos. Crea la Agencia Nacional de Ciberseguridad (ANCI) con poderes de supervisi√≥n y sanci√≥n. CR√çTICO para el CISO: los sistemas de IA desplegados en infraestructura cr√≠tica, servicios financieros, telecomunicaciones, salud, energ√≠a o gobierno est√°n directamente bajo esta ley. Requiere: gesti√≥n de riesgos, notificaci√≥n de incidentes, seguridad por dise√±o.                                                            |
| Agencia de Protecci√≥n de Datos Personales | La Ley No. 21.719 de Protecci√≥n de Datos (aprobada 2024) moderniza el marco de privacidad chileno, creando la Agencia de Protecci√≥n de Datos Personales. Aplica a sistemas de IA que procesan datos personales, incluyendo decisiones automatizadas, perfilamiento y procesamiento biom√©trico. Estar√° plenamente operativa en el curso de 2026.                                                                                                                                                                                                                                    |
| Posici√≥n regional                         | Chile lidera el √çndice Latinoamericano de Inteligencia Artificial (ILIA 2025) junto con Brasil y Uruguay, con puntajes superiores a 60 puntos. El CENIA (Centro Nacional de IA de Chile) coordina la gobernanza nacional. Para el CISO con operaciones o clientes en Chile: la Ley Marco de Ciberseguridad 21.663 ya est√° vigente y es de aplicaci√≥n inmediata.                                                                                                                                                                                                                    |

<br>

### Otros Pa√≠ses LATAM: Estado Legislativo 2026

| PA√çS          | MADUREZ  | INSTRUMENTO CLAVE                         | ESTADO ACTUAL                                                                                                                                                                | IMPACTO PARA CISO ARG                                                                                                |
| ------------- | -------- | ----------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------- |
| üá®üá¥ Colombia | Adopter  | Nuevo proyecto de ley (2025)              | Marco de autorregulaci√≥n, √©tica y transparencia. M√∫ltiples proyectos previos fallidos. Propuesta 2025 centrada en innovaci√≥n y derechos fundamentales.                       | Bajo impacto directo. Monitorear si hay operaciones en Colombia.                                                     |
| üá≤üáΩ M√©xico   | Explorer | Estrategia Nacional de IA (no vinculante) | Propuestas en el Congreso pero sin avance legislativo concreto. El INAI (autoridad de datos) aplica marco de protecci√≥n de datos existente a sistemas de IA.                 | Bajo impacto normativo directo. Ley Federal de Protecci√≥n de Datos vigente aplica a operaciones con datos mexicanos. |
| üáµüá™ Per√∫     | Adopter  | Ley No. 31814 (2023, vigente)             | Primera ley de IA vinculante de la regi√≥n en sentido amplio. Marco de tres niveles: prohibido, alto riesgo, bajo riesgo. √ânfasis en derechos humanos y desarrollo econ√≥mico. | Monitorear si hay clientes/operaciones en Per√∫. Ley vigente con enforcement limitado.                                |
| üá∫üáæ Uruguay  | Pioneer  | Ley de Datos vigente + Estrategia IA      | Uno de los tres 'pioneros' seg√∫n ILIA 2025. Marco de protecci√≥n de datos robusto reconocido por UE como adecuado. Sin ley espec√≠fica de IA pero gobernanza madura.           | Uruguay tiene reconocimiento de adecuaci√≥n UE ‚Äî datos de ciudadanos uruguayos tienen protecciones m√°s fuertes.       |
| üáµüá¶ Panam√°   | Explorer | Propuestas en Asamblea Nacional           | Iniciativas legislativas de IA en consideraci√≥n. Derechos digitales del ciudadano como foco central.                                                                         | Sin impacto directo inmediato.                                                                                       |
| üá™üá® Ecuador  | Adopter  | Estrategia Nacional IA + PDPA             | Adoptador seg√∫n ILIA 2025. Marco de protecci√≥n de datos existente. Sin ley espec√≠fica de IA.                                                                                 | PDPA ecuatoriana aplica a datos de ciudadanos ecuatorianos procesados por organizaciones argentinas.                 |

<br>

## 11.2 EL IMPACTO EXTRATERRITORIAL DEL EU AI ACT EN ARGENTINA

<br>

El EU AI Act (Reglamento UE 2024/1689, vigente desde agosto de 2024) tiene un alcance extraterritorial similar al del GDPR: aplica a sistemas de IA que son utilizados en la Uni√≥n Europea, independientemente de donde se desarrollen o desplieguen. Para una organizaci√≥n argentina con clientes europeos, partners con sede en la UE, o datos de ciudadanos europeos en sus sistemas, el EU AI Act no es una regulaci√≥n ajena ‚Äî es una obligaci√≥n activa.

<br>

### 11.2.1 ¬øA Qu√© Organizaciones Argentinas Aplica el EU AI Act?

| ESCENARIO                                                                                                                                       | APLICA EU AI ACT                                                                                                                                                                                                                                                                                   |
| ----------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Proveedor argentino que vende software con IA a empresas o usuarios en la UE                                                                    | S√ç. El proveedor es un 'provider' bajo el EU AI Act. Debe cumplir los requisitos del nivel de riesgo del sistema, incluyendo documentaci√≥n t√©cnica, evaluaciones de conformidad y marcado CE para sistemas de alto riesgo.                                                                         |
| Empresa argentina que usa un sistema de IA para procesar datos de empleados o clientes europeos                                                 | S√ç para sistemas de alto riesgo (ej: scoring crediticio, decisiones de RRHH, biometr√≠a). La empresa act√∫a como 'deployer' y tiene obligaciones de supervisi√≥n humana, transparencia con el afectado, y cumplimiento con la pol√≠tica de uso del proveedor.                                          |
| Empresa argentina que procesa datos de ciudadanos europeos como parte de su servicio (ej: filial de empresa europea, BPO con clientes europeos) | S√ç, combinando GDPR (datos personales) y EU AI Act (si los sistemas de IA usados son de alto riesgo o afectan a europeos).                                                                                                                                                                         |
| Empresa argentina con socios europeos que exigen compliance contractual como parte de su cadena de suministro                                   | DE FACTO. Aunque no haya obligaci√≥n legal directa, los contratos B2B con socios europeos incorporar√°n cada vez m√°s cl√°usulas de compliance EU AI Act como requisito para la relaci√≥n comercial. Ya ocurre con GDPR desde 2018.                                                                     |
| Empresa argentina sin exposici√≥n a la UE ‚Äî sin clientes, empleados ni datos europeos                                                            | NO directamente. Sin embargo: ISO 42001 (el est√°ndar de gesti√≥n de IA m√°s influyente) est√° alineado con el EU AI Act y se est√° convirtiendo en requisito de facto en licitaciones globales y enterprise.                                                                                           |
| Microsoft Argentina como filial de empresa europea (Microsoft Corp. tiene base en UE)                                                           | El CISO de Microsoft Argentina opera bajo las obligaciones EU AI Act de Microsoft Corp., que aplica como provider de M365, Defender y Security Copilot. Las pol√≠ticas de Microsoft ya est√°n alineadas con EU AI Act. El CISO debe entender este alineamiento para sus propias pol√≠ticas derivadas. |

<br>

### 11.2.2 Calendario EU AI Act: Deadlines Cr√≠ticos para el CISO

| FECHA        | EVENTO REGULATORIO                          | OBLIGACI√ìN OPERACIONAL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| ------------ | ------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Agosto 2024  | Entrada en vigor (publicaci√≥n)              | El Reglamento es ley de la UE. El reloj de los plazos de implementaci√≥n comienza.                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| Febrero 2025 | Pr√°cticas de IA PROHIBIDAS vigentes         | PROHIBIDO desde esta fecha en la UE: (1) sistemas de puntuaci√≥n social por autoridades p√∫blicas, (2) IA que manipule el comportamiento mediante t√©cnicas subliminales, (3) explotaci√≥n de vulnerabilidades de grupos espec√≠ficos, (4) reconocimiento biom√©trico en tiempo real en espacios p√∫blicos (con excepciones), (5) inferencia de emociones en trabajo/educaci√≥n, (6) categorizaci√≥n biom√©trica por caracter√≠sticas sensibles. Verificar que ning√∫n sistema propio caiga en estas categor√≠as si se usa para europeos. |
| Agosto 2025  | Normas de Governance de GPAI vigentes       | Los modelos de prop√≥sito general de alto impacto sist√©mico (como GPT-4, Claude, Gemini) tienen nuevas obligaciones. Como deployer, entender los compromisos de los proveedores bajo este cap√≠tulo.                                                                                                                                                                                                                                                                                                                           |
| Agosto 2026  | Sistemas de ALTO RIESGO (Anexos III y IV)   | Sistemas de IA de alto riesgo deben cumplir todos los requisitos: documentaci√≥n t√©cnica, evaluaci√≥n de conformidad, supervisi√≥n humana, logs de auditor√≠a, data governance. ¬øCu√°les son de alto riesgo? Infraestructura cr√≠tica, biometr√≠a, empleo y RRHH (scoring, selecci√≥n), cr√©dito y scoring financiero, justicia, acceso a servicios p√∫blicos esenciales. DEADLINE: 12 meses. Hoja de ruta de compliance debe comenzar HOY.                                                                                            |
| Agosto 2027  | Plena aplicaci√≥n de supervisi√≥n post-market | Vigilancia de mercado y mecanismos de intercambio de informaci√≥n. Autoridades nacionales con poderes de inspecci√≥n. Las multas se vuelven operativas: hasta ‚Ç¨35M o 7% de facturaci√≥n global para incumplimientos graves.                                                                                                                                                                                                                                                                                                     |

<br>

‚ö†Ô∏è Agosto 2026 es el deadline m√°s urgente: Los sistemas de IA de alto riesgo deben estar en cumplimiento en agosto de 2026 ‚Äî a 6 meses de la fecha de corte de este informe. El CISO con exposici√≥n a la UE debe iniciar el inventario de sistemas de alto riesgo de inmediato. No hacerlo a tiempo expone a la organizaci√≥n a sanciones de hasta ‚Ç¨35M o 7% de facturaci√≥n global.

<br>

## 11.3 ARGENTINA EN DETALLE: MARCO VIGENTE Y REFORMA 2025

<br>

Argentina tiene uno de los marcos de protecci√≥n de datos personales m√°s antiguos de Am√©rica Latina ‚Äî la Ley 25.326 data del a√±o 2000 ‚Äî pero tambi√©n uno de los m√°s desactualizados frente a los desaf√≠os de la IA, el cloud y la econom√≠a de datos. En 2025, se abri√≥ por primera vez una ventana legislativa seria para la modernizaci√≥n. El CISO necesita entender tanto el r√©gimen vigente como el que viene.

<br>

### 11.3.1 Marco Vigente: Ley 25.326 y sus Implicancias para Sistemas de IA

| PRINCIPIO / OBLIGACI√ìN                      | TEXTO VIGENTE (LEY 25.326)                                                                                                                                                           | IMPACTO EN SISTEMAS DE IA                                                                                                                                                                                                                                                                                                                                                                                                                     |
| ------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Consentimiento informado                    | Art. 5: El tratamiento de datos personales requiere el consentimiento libre, expreso e informado del titular.                                                                        | Los sistemas de IA que procesen datos personales (incluyendo comportamiento, perfiles, decisiones crediticias) requieren base legal v√°lida. El consentimiento no puede ser impl√≠cito. Los sistemas de decisi√≥n automatizada basados en datos de clientes sin consentimiento expl√≠cito son observables.                                                                                                                                        |
| Calidad de los datos                        | Art. 4: Los datos deben ser exactos, completos, actualizados y adecuados al fin para el que fueron recopilados.                                                                      | Obliga a pol√≠ticas de data quality para los datasets usados en entrenamiento o inferencia. Datos desactualizados o incorrectos en modelos de IA pueden generar liability bajo la ley.                                                                                                                                                                                                                                                         |
| Datos sensibles                             | Art. 2: Los datos que revelan origen racial, √©tnico, opiniones pol√≠ticas, religiosas, filos√≥ficas, sindicales, informaci√≥n sobre salud o vida sexual requieren protecci√≥n reforzada. | Los proyectos de IA que usen datos biom√©tricos, de salud o de comportamiento que infiera caracter√≠sticas sensibles requieren an√°lisis especial. La Ley 25.326 es m√°s restrictiva que el GDPR en este punto.                                                                                                                                                                                                                                   |
| Derecho de acceso y correcci√≥n              | Arts. 14-16: El titular tiene derecho a acceder, rectificar, actualizar y suprimir sus datos en cualquier momento.                                                                   | Los sistemas de IA deben ser dise√±ados para responder a solicitudes de acceso y supresi√≥n. Si un sistema de IA tom√≥ una decisi√≥n basada en datos incorrectos, el titular puede impugnar esa decisi√≥n.                                                                                                                                                                                                                                         |
| Derecho a impugnar decisiones automatizadas | Art. 16 inc. 3: El titular puede impugnar las evaluaciones sobre su conducta o personalidad efectuadas mediante tratamientos automatizados.                                          | Aplicable a scoring crediticio, evaluaciones de riesgo, perfiles de comportamiento generados por IA. El sistema de IA debe poder ser explicado y la decisi√≥n revisada por un humano. Compliance actual: muchos sistemas de IA argentinos no tienen este mecanismo implementado.                                                                                                                                                               |
| Autoridad de aplicaci√≥n                     | AAIP (Agencia de Acceso a la Informaci√≥n P√∫blica): Registro, fiscalizaci√≥n, sanciones (apercibimiento, multas, suspensi√≥n de base de datos).                                         | La AAIP tiene jurisdicci√≥n sobre el uso de datos en sistemas de IA. El CISO debe registrar las bases de datos ante la AAIP (Registro Nacional de Bases de Datos) ‚Äî incumplimiento es infracci√≥n sancionable.                                                                                                                                                                                                                                  |
| Transferencia internacional                 | Art. 12: La transferencia de datos a pa√≠ses sin nivel de protecci√≥n adecuado est√° prohibida sin autorizaci√≥n de la AAIP.                                                             | Relevante para sistemas de IA que env√≠en datos a proveedores cloud en EE.UU., Asia o cualquier pa√≠s sin reconocimiento de adecuaci√≥n. Microsoft, Google y AWS tienen mecanismos de transferencia aprobados ‚Äî pero el CISO debe verificar la configuraci√≥n espec√≠fica (ZDR, data residency). NOTA: Argentina tiene reconocimiento de adecuaci√≥n por parte de la UE (Decisi√≥n 2003/490/CE) ‚Äî esto facilita transferencias en ambas direcciones. |

<br>

### 11.3.2 Reforma Propuesta: Proyectos Carro/Do√±ate 2025

Dos proyectos de ley presentados en 2025 proponen la reforma integral de la Ley 25.326. Ambos se inspiran en el anteproyecto de la AAIP (que perdi√≥ estado parlamentario en 2024) y buscan alinear Argentina con el GDPR europeo y la LGPD brasile√±a.

| NOVEDAD RESPECTO A LEY VIGENTE                          | TEXTO PROPUESTO                                                                                                                                              | IMPACTO PARA EL CISO Y SISTEMAS DE IA                                                                                                                                                                                                 |
| ------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Responsabilidad proactiva y demostrada (accountability) | El responsable del tratamiento debe poder demostrar el cumplimiento, no solo declararlo. Incorpora Privacy by Design y Privacy by Default como obligaciones. | El CISO debe poder documentar que todos los sistemas de IA fueron dise√±ados con privacidad desde el inicio. Los registros de actividades de procesamiento (RAP) son ahora obligatorios y exigibles.                                   |
| Portabilidad de datos                                   | Nuevo derecho: el titular puede solicitar que sus datos sean transferidos a otro responsable en formato estructurado y de uso com√∫n.                         | Los sistemas de IA que usen datos de clientes deben dise√±arse para exportar esos datos en formato portable. Impacto en arquitectura de datos y sistemas core.                                                                         |
| Oposici√≥n a decisiones automatizadas                    | Derecho expl√≠cito a oponerse a decisiones que produzcan efectos jur√≠dicos o que le afecten negativamente, tomadas exclusivamente por sistemas automatizados. | Los modelos de IA que toman decisiones de alto impacto (cr√©dito, RRHH, precios, acceso a servicios) deben tener una v√≠a de revisi√≥n humana habilitada. El CISO debe inventariar estos sistemas y documentar el proceso de revisi√≥n.   |
| Sandbox regulatorio                                     | Autorizaci√≥n temporal a proyectos piloto de innovaci√≥n tecnol√≥gica en un entorno controlado, bajo supervisi√≥n de la AAIP.                                    | Oportunidad para proyectos de IA que requieran flexibilidad regulatoria transitoria. El CISO puede proponer casos de uso innovadores para el sandbox antes de la implementaci√≥n a escala.                                             |
| Datos biom√©tricos como datos sensibles                  | Los datos biom√©tricos se incorporan expl√≠citamente al listado de datos sensibles con protecci√≥n reforzada.                                                   | Sistemas de IA que usen reconocimiento facial, huella dactilar, voz u otras caracter√≠sticas biom√©tricas requerir√°n consentimiento expl√≠cito y evaluaci√≥n de impacto. Impacto en sistemas de acceso f√≠sico, autenticaci√≥n y monitoreo. |
| Evaluaci√≥n de Impacto de Datos Personales (EIMPD)       | Obligatoria cuando el tratamiento pueda causar grave afectaci√≥n a los titulares.                                                                             | Todos los sistemas de IA de alto impacto deben tener una EIMPD documentada antes del deployment. Similar al DPIA del GDPR pero adaptado al contexto argentino.                                                                        |
| Plazo de adecuaci√≥n                                     | Los proyectos proponen solo 6 meses de per√≠odo de adecuaci√≥n tras la aprobaci√≥n (vs. 2 a√±os del GDPR y la LGPD).                                             | Si la ley se aprueba en 2025-2026, el CISO tiene un plazo muy corto para adaptar todos los sistemas. Es imperativo comenzar el compliance ANTES de la aprobaci√≥n, usando como gu√≠a el texto de los proyectos actuales.                |

<br>

### 11.3.3 Proyecto S-0071/2025: Regulaci√≥n de IA en Argentina

| ELEMENTO                 | DESCRIPCI√ìN                                                                                                                                                                                                                              |
| ------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Presentaci√≥n             | Presentado en el Senado el 5 de marzo de 2025. Primer proyecto integral de regulaci√≥n de IA en Argentina con estado parlamentario activo en 2025-2026.                                                                                   |
| Objeto                   | Establecer controles y principios rectores para el desarrollo, implementaci√≥n y utilizaci√≥n de sistemas de IA dentro del territorio argentino. Foco en salvaguardar la dignidad, los derechos humanos y el bienestar.                    |
| Clasificaci√≥n de riesgo  | Cuatro niveles: (1) Riesgo m√≠nimo, (2) Riesgo limitado, (3) Riesgo alto, (4) Riesgo inaceptable. Similar a EU AI Act. Los sistemas de riesgo inaceptable est√°n prohibidos.                                                               |
| Registro Nacional        | Obliga a entidades p√∫blicas y privadas a registrarse en un Registro Nacional de Sistemas de IA y someterse a evaluaciones de impacto.                                                                                                    |
| Prohibiciones expl√≠citas | Proh√≠be IA en pr√°cticas que amenacen derechos fundamentales, incluyendo vigilancia biom√©trica masiva en tiempo real en espacios p√∫blicos.                                                                                                |
| Enfoque Argentina 2026   | Argentina busca deliberadamente un enfoque menos regulado que la UE para atraer inversi√≥n extranjera y fomentar la innovaci√≥n. Sin embargo, el proyecto S-0071/2025 introduce m√≠nimos de protecci√≥n que las empresas deben anticipar.    |
| Estado actual            | En comisiones del Senado. Sin fecha definida de tratamiento en pleno. Los proyectos de ley de IA en Argentina tienen tendencia hist√≥rica a perderse entre sesiones. El CISO debe monitorear pero no depender de su aprobaci√≥n para 2026. |

<br>

## 11.4 AN√ÅLISIS DE BRECHAS: COMPLIANCE MATRIX PARA EL CISO EN ARGENTINA

<br>

Esta matriz consolida los requisitos de los marcos regulatorios m√°s relevantes para el CISO que opera en Argentina con potencial exposici√≥n a Brasil, Chile y la Uni√≥n Europea. Para cada obligaci√≥n, se indica el estado t√≠pico de compliance de una organizaci√≥n argentina que a√∫n no ha iniciado un programa formal de compliance de IA, y la acci√≥n prioritaria.

<br>

Leyenda: ‚úÖ Generalmente cumplido con controles existentes | ‚ö†Ô∏è Parcialmente ‚Äî requiere mejora | ‚ùå Brecha ‚Äî requiere acci√≥n prioritaria

<br>

### Dimensi√≥n 1: Gobernanza y Documentaci√≥n

| OBLIGACI√ìN                                             | Ley 25.326(ARG vigente) | Reforma ARG(proyectos 2025) | EU AI Act(si aplica) | ACCI√ìN PRIORITARIA                                                                                                                                                               |
| ------------------------------------------------------ | ----------------------- | --------------------------- | -------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Inventario de todos los sistemas de IA                 | ‚ö†Ô∏è                      | ‚ùå                           | ‚ùå                    | Ejecutar inventario de IA en 30 d√≠as. Para cada sistema: nombre, proveedor, datos que procesa, nivel de riesgo estimado, usuarios. Base para todo el compliance.                 |
| Registro de Actividades de Procesamiento (RAP)         | ‚ö†Ô∏è                      | ‚ùå                           | ‚ùå                    | Extender el registro de bases de datos ante la AAIP para incluir todos los sistemas de IA que procesan datos personales. Bajo ley vigente ya es obligatorio el registro en RNBD. |
| Evaluaci√≥n de Impacto de Datos Personales (EIMPD/DPIA) | ‚ùå                       | ‚ùå                           | ‚ùå (alto riesgo)      | Implementar proceso de DPIA para todos los sistemas de IA existentes y nuevos. Priorizar: sistemas que procesan datos de empleados, clientes y datos financieros.                |
| Documentaci√≥n t√©cnica de sistemas de IA                | ‚ùå                       | ‚ùå                           | ‚ùå (alto riesgo)      | Crear 'fichas de sistema de IA' para cada herramienta en producci√≥n: prop√≥sito, datos de entrenamiento, precisi√≥n, limitaciones, sesgos identificados, versi√≥n del modelo.       |
| Pol√≠tica de uso aceptable de IA                        | ‚ö†Ô∏è                      | ‚ùå                           | ‚ö†Ô∏è                   | Publicar y comunicar pol√≠tica de uso de IA que cubra: herramientas aprobadas, usos prohibidos, Shadow AI, datos que no pueden compartirse con IA externas.                       |
| AI Governance Committee activo                         | ‚ùå                       | ‚ùå                           | ‚ö†Ô∏è                   | Formalizar el comit√© con mandato, qu√≥rum, frecuencia de reuni√≥n y documentaci√≥n de decisiones. Sin este cuerpo, el resto del compliance no tiene ancla institucional.            |

<br>

### Dimensi√≥n 2: Derechos de los Titulares

| OBLIGACI√ìN                                            | Ley 25.326 | Reforma ARG 2025 | EU AI Act                    | ACCI√ìN PRIORITARIA                                                                                                                                                                                    |
| ----------------------------------------------------- | ---------- | ---------------- | ---------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Informaci√≥n al titular sobre decisiones automatizadas | ‚ö†Ô∏è         | ‚ùå                | ‚ùå                            | Actualizar avisos de privacidad para incluir menci√≥n expl√≠cita de sistemas de IA y decisiones automatizadas. Lenguaje claro, no t√©cnico.                                                              |
| Derecho a impugnar decisiones automatizadas           | ‚ö†Ô∏è         | ‚ùå                | ‚ùå (alto riesgo)              | Implementar proceso de revisi√≥n humana para todas las decisiones automatizadas de alto impacto. Documentar el proceso y comunicarlo al titular antes de la decisi√≥n.                                  |
| Portabilidad de datos                                 | ‚ùå          | ‚ùå                | N/A (requisito sectorial EU) | Aunque no es obligatorio a√∫n bajo ley argentina vigente, preparar la arquitectura de datos para soportar portabilidad. La reforma lo requerir√° con solo 6 meses de plazo.                             |
| Derecho de acceso / supresi√≥n en sistemas de IA       | ‚ö†Ô∏è         | ‚ùå                | N/A                          | Verificar que los sistemas de IA puedan responder a solicitudes de acceso, rectificaci√≥n y supresi√≥n. Datos de entrenamiento que incluyan PII requieren un proceso de 'olvido' t√©cnicamente complejo. |
| Transparencia sobre uso de datos biom√©tricos          | ‚ùå          | ‚ùå                | ‚ùå                            | Si la organizaci√≥n usa reconocimiento facial, huella digital o voz para identificaci√≥n: implementar consentimiento expl√≠cito y separado del consentimiento general.                                   |

<br>

### Dimensi√≥n 3: Seguridad T√©cnica y Operacional de Sistemas de IA

| OBLIGACI√ìN                                        | Ley 25.326 | Reforma ARG 2025 | EU AI Act       | ACCI√ìN PRIORITARIA                                                                                                                                                                                   |
| ------------------------------------------------- | ---------- | ---------------- | --------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Seguridad de los datos usados por sistemas de IA  | ‚ö†Ô∏è         | ‚ùå                | ‚ùå (alto riesgo) | Extender el framework de seguridad de datos (BCRA, ISO 27001) expl√≠citamente a los data pipelines de IA: datos de entrenamiento, datos de inferencia, outputs del modelo.                            |
| Logs inmutables de decisiones automatizadas       | ‚ùå          | ‚ùå                | ‚ùå (alto riesgo) | Implementar audit logs inmutables para todas las decisiones automatizadas de alto impacto. Retenci√≥n m√≠nima: 3 a√±os. Incluir: input, output, versi√≥n del modelo, timestamp, usuario afectado.        |
| Monitoreo de drift y degradaci√≥n del modelo       | ‚ùå          | ‚ùå                | ‚ùå (alto riesgo) | Implementar monitoreo continuo de performance de modelos en producci√≥n. Alert thresholds para detecci√≥n de drift. Proceso de revalidaci√≥n cuando el modelo se degrada.                               |
| Pruebas de sesgo (bias testing)                   | ‚ùå          | ‚ùå                | ‚ùå               | Antes del deployment de cualquier sistema de IA que afecte decisiones sobre personas: ejecutar pruebas de sesgo sistem√°ticas. Documentar metodolog√≠a y resultados.                                   |
| Notificaci√≥n de brechas de seguridad (AI systems) | ‚ö†Ô∏è         | ‚ùå                | ‚ö†Ô∏è              | Extender el proceso de breach notification (Ley 25.326 + BCRA si aplica) a incidentes espec√≠ficos de seguridad en sistemas de IA: prompt injection exitoso, data poisoning, exfiltraci√≥n v√≠a agente. |
| Supervisi√≥n humana de sistemas de alto riesgo     | ‚ùå          | ‚ùå                | ‚ùå               | Para cada sistema de IA de alto impacto: definir expl√≠citamente qui√©n es el responsable humano, con qu√© frecuencia revisa las decisiones, y c√≥mo puede anular o corregir una decisi√≥n del sistema.   |

<br>

### Dimensi√≥n 4: Transferencia Internacional de Datos en Sistemas de IA

| ESCENARIO                                                             | MARCO APLICABLE                                                                                                                  | CONTROL REQUERIDO                                                                                                                                                                                                           |
| --------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Datos de clientes argentinos procesados en Azure (Microsoft)          | Ley 25.326 Art. 12 + Cla√∫sulas Contractuales Tipo. Argentina tiene adecuaci√≥n EU reconocida en Decisi√≥n 2003/490/CE.             | Verificar que la regi√≥n de Azure configurada sea argentina (South America) o que exista DPA firmado. Microsoft Argentina tiene compromisos de datos con el gobierno. Ver Fase 6 del informe para an√°lisis contractual.      |
| Datos de ciudadanos europeos procesados por la organizaci√≥n argentina | GDPR (obligatorio si la org procesa datos de europeos). EU AI Act si el sistema es de alto riesgo.                               | DPA con todos los proveedores sub-encargados. ZDR (Zero Data Retention) para inferencias con datos europeos. Cl√°usulas contractuales tipo entre la entidad argentina y el responsable europeo.                              |
| Datos de ciudadanos brasile√±os procesados en Argentina                | LGPD (Lei Geral de Prote√ß√£o de Dados brasile√±a) aplica extraterritorialmente.                                                    | La LGPD aplica si los datos son de personas en Brasil o si la actividad tiene por objeto ofertar bienes/servicios a personas en Brasil. DPA con la organizaci√≥n brasile√±a. Registros de actividad de tratamiento bajo LGPD. |
| Uso de APIs de IA (Anthropic/OpenAI/Google) que transmiten datos      | Ley 25.326 Art. 12 requiere que el pa√≠s destinatario tenga nivel adecuado de protecci√≥n o que se usen mecanismos alternativos.   | ZDR addendum con el proveedor (Fase 6). Verificar que el DPA del proveedor est√© vigente. No enviar datos sensibles sin ZDR confirmado. Revisar configuraci√≥n de data residency en las APIs.                                 |
| DeepSeek o cualquier proveedor con datos almacenados en China         | Incompatible con Ley 25.326 (China no tiene nivel adecuado de protecci√≥n de datos). Incompatible con GDPR si hay datos europeos. | PROHIBIDO para datos personales de cualquier jurisdicci√≥n analizada. Bloqueo a nivel de Entra Internet Access (AI web category filter). Pol√≠tica expl√≠cita en el AI Usage Policy.                                           |

<br>

## 11.5 ESTRATEGIA DE COMPLIANCE: 12 MESES PARA EL CISO EN ARGENTINA

<br>

El plan de 12 meses integra los requisitos regulatorios de la Fase 11 con las capacidades t√©cnicas del ecosistema Microsoft (Fases 7-10) y el framework de gobernanza de la Fase 7. Est√° dise√±ado para organizaciones que operan bajo la Ley 25.326 vigente, con exposici√≥n potencial al EU AI Act (agosto 2026) y que anticipan la reforma argentina del marco de datos.

<br>

### TRIMESTRE 1 (Meses 1-3): Visibilidad y Baseline Regulatorio

| <p><br></p> | ACCI√ìN                                                                                                                                                                                                                                                                  | MARCO REGULATORIO                                                                    | OUTPUT                                                                                                         |
| ----------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------- |
| 1           | Inventario completo de sistemas de IA: herramientas internas, SaaS con componente de IA, APIs de proveedores, agentes de Copilot Studio. Para cada sistema: datos procesados, usuarios afectados, decisiones que genera, proveedor, contrato.                           | Ley 25.326 (RNBD), Reform ARG (accountability), EU AI Act (documentaci√≥n t√©cnica)    | Registro maestro de sistemas de IA. Base para toda la clasificaci√≥n de riesgo y el compliance.                 |
| 2           | Clasificaci√≥n de riesgo de cada sistema usando la taxonom√≠a de cuatro niveles (alineada con EU AI Act y S-0071/2025): Inaceptable / Alto / Limitado / M√≠nimo. Criterios: impacto en personas, uso de datos sensibles, nivel de autonom√≠a, reversibilidad de decisiones. | EU AI Act Anexos I y III, S-0071/2025, Gu√≠a OCDE                                     | Tabla de clasificaci√≥n de riesgos aprobada por el AI Governance Committee.                                     |
| 3           | Auditor√≠a de contratos con proveedores de IA: verificar que todos tengan DPA firmado, ZDR para datos sensibles, cl√°usula de indemnizaci√≥n IP, y definici√≥n de qu√© datos se usan para entrenamiento.                                                                     | Ley 25.326 Art. 12 (transferencia), GDPR (si hay datos europeos), an√°lisis de Fase 6 | Matriz de contratos: provider / DPA firmado / ZDR / residencia datos / vencimiento.                            |
| 4           | Registro ante la AAIP de todas las bases de datos de sistemas de IA que procesen datos personales. Verificar que el RNBD est√© actualizado con todos los sistemas actuales.                                                                                              | Ley 25.326 Art. 21 (obligaci√≥n vigente e inmediata)                                  | Inscripciones actualizadas en RNBD. Evidencia de cumplimiento regulatorio ante cualquier auditor√≠a de la AAIP. |
| 5           | Evaluaci√≥n del impacto del EU AI Act: ¬øLa organizaci√≥n tiene sistemas que operen para/con usuarios en la UE? ¬øHay contratos con empresas europeas que impliquen procesamiento de datos de europeos? Determinar el nivel de exposici√≥n real.                             | EU AI Act Art√≠culo 2 (√°mbito de aplicaci√≥n extraterritorial)                         | Dictamen jur√≠dico sobre exposici√≥n EU AI Act. Define la urgencia del compliance europeo.                       |

<br>

### TRIMESTRE 2 (Meses 4-6): Controles T√©cnicos para Sistemas de Alto Impacto

| <p><br></p> | ACCI√ìN                                                                                                                                                                                                                                         | MARCO REGULATORIO                                                                         | OUTPUT                                                                                              |
| ----------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| 6           | Implementar EIMPD (Evaluaci√≥n de Impacto de Datos Personales) para todos los sistemas de IA clasificados como alto riesgo o con uso de datos sensibles. Priorizar: scoring crediticio, sistemas de RRHH, perfilamiento de clientes, biometr√≠a. | Reforma ARG 2025 (EIMPD), EU AI Act Art. 9 y 10 (DPIA)                                    | EIMPDs documentadas para sistemas de alto riesgo. Archivo permanente con metodolog√≠a y resultados.  |
| 7           | Dise√±ar e implementar el proceso de revisi√≥n humana para decisiones automatizadas de alto impacto. ¬øQui√©n es el responsable? ¬øEn qu√© plazo? ¬øC√≥mo se comunica al afectado? Actualizar avisos de privacidad.                                    | Ley 25.326 Art. 16 inc. 3 (vigente), Reforma ARG 2025, EU AI Act Art. 22                  | Proceso documentado de revisi√≥n humana. Avisos de privacidad actualizados con menci√≥n de IA.        |
| 8           | Implementar logs inmutables de decisiones automatizadas para sistemas de alto riesgo. En Microsoft Purview: configurar retenci√≥n de audit logs (m√≠nimo 3 a√±os) para acciones cr√≠ticas de sistemas de IA.                                       | EU AI Act Art. 12 (alto riesgo), Reforma ARG 2025 (accountability)                        | Audit logs configurados y verificados para sistemas de alto riesgo. Evidencia de inmutabilidad.     |
| 9           | Ejecutar pruebas de sesgo (bias testing) en los modelos de IA de mayor impacto social. Documentar metodolog√≠a, resultados y plan de mitigaci√≥n para los sesgos identificados.                                                                  | EU AI Act Art. 10 (datos de entrenamiento), S-0071/2025 (principios de no discriminaci√≥n) | Informe de bias testing por sistema. Plan de mitigaci√≥n con responsables y plazos.                  |
| 10          | Actualizar el AI Usage Policy con: lista aprobada de herramientas, clasificaci√≥n de datos que pueden y no pueden compartirse, proceso de aprobaci√≥n de nuevas herramientas (SLA 48h para bajo riesgo), consecuencias de Shadow AI.             | Ley 25.326 (base legal para tratamiento), Reforma ARG 2025                                | Pol√≠tica publicada, comunicada y firmada por todos los empleados. Training obligatorio documentado. |

<br>

### TRIMESTRE 3 (Meses 7-9): EU AI Act ‚Äî Sistemas de Alto Riesgo

| <p><br></p> | ACCI√ìN                                                                                                                                                                                                                                                           | MARCO REGULATORIO                                                                 | OUTPUT                                                                                                       |
| ----------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ |
| 11          | Para cada sistema identificado como de alto riesgo bajo EU AI Act: preparar la documentaci√≥n t√©cnica requerida (Art. 11): descripci√≥n del sistema, datos de entrenamiento, metodolog√≠a, limitaciones, medidas de supervisi√≥n humana, indicadores de rendimiento. | EU AI Act Art. 11 y Anexo IV                                                      | Expedientes t√©cnicos de sistemas de alto riesgo. Listos para revisi√≥n de autoridad supervisora.              |
| 12          | Implementar el proceso de monitoreo post-deployment para sistemas de alto riesgo: m√©tricas de rendimiento, detecci√≥n de drift, incidentes adversos, escalaci√≥n a proveedor cuando corresponda.                                                                   | EU AI Act Art. 9 (sistema de gesti√≥n de riesgos), Art. 61 (monitoreo post-market) | Dashboard de monitoreo de sistemas de alto riesgo. Proceso de reporte de incidentes activado.                |
| 13          | Preparar el proceso de registro de sistemas de alto riesgo ante la base de datos EU (EU Database for High-Risk AI, Art. 71 EU AI Act), si la exposici√≥n europea lo requiere.                                                                                     | EU AI Act Art. 71 (GPAI model registration)                                       | An√°lisis de qu√© sistemas requieren registro EU. Proceso iniciado con el equipo legal europeo si corresponde. |
| 14          | Realizar tabletop exercise de respuesta a incidente regulatorio: ¬øC√≥mo responder√≠a la organizaci√≥n ante una inspecci√≥n de la AAIP? ¬øAnte una notificaci√≥n de la autoridad supervisora europea?                                                                   | Ley 25.326, EU AI Act Art. 79 (market surveillance)                               | Playbook de respuesta a inspecci√≥n regulatoria. Identificaci√≥n de gaps en documentaci√≥n disponible.          |

<br>

### TRIMESTRE 4 (Meses 10-12): ISO 42001, Scorecard y Anticipaci√≥n

| <p><br></p> | ACCI√ìN                                                                                                                                                                                                                                                                                                                                    | MARCO REGULATORIO                                                    | OUTPUT                                                                                                                  |
| ----------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| 15          | Iniciar la implementaci√≥n de ISO 42001 (AI Management System) como marco de gobernanza transversal. ISO 42001 es el est√°ndar internacional de gesti√≥n de IA, alineado con EU AI Act, NIST AI RMF y los marcos nacionales emergentes. Se convierte en requisito de facto en licitaciones enterprise y contratos con grandes corporaciones. | ISO/IEC 42001:2023, EU AI Act (conformidad alternativa), NIST AI RMF | Plan de implementaci√≥n ISO 42001. Definici√≥n del alcance, gap analysis ISO, designaci√≥n del AI Management System Owner. |
| 16          | Actualizar el Scorecard de Madurez de Gobernanza de IA (de la Fase 7.8) con los resultados del a√±o de compliance. Presentar al Board: progreso desde el baseline, brechas residuales, plan del pr√≥ximo a√±o.                                                                                                                               | Todas las fases del informe                                          | Scorecard actualizado. Presentaci√≥n Board: estado de compliance, riesgos residuales, inversi√≥n requerida.               |
| 17          | Monitorear el avance de la reforma de la Ley 25.326 y el proyecto S-0071/2025. Si hay aprobaci√≥n: activar el plan de adecuaci√≥n de 6 meses de forma inmediata. Si no hay aprobaci√≥n: las acciones previas ya anticipan el 80% de los requisitos.                                                                                          | Reforma ARG 2025, S-0071/2025                                        | Estado de la legislaci√≥n en el Congreso. Plan contingente de adecuaci√≥n listo para activarse.                           |
| 18          | Preparar el caso de negocio para ISO 42001 y/o SOC 2 Type II como credenciales de compliance de IA para el mercado: diferenciadores en licitaciones, reducci√≥n de prima de seguro cibern√©tico, habilitaci√≥n de contratos con empresas europeas.                                                                                           | ISO 42001, SOC 2, EU AI Act (confianza del mercado)                  | Business case para certificaci√≥n de compliance de IA. Con datos de la Fase 9 (ROI de la gobernanza).                    |

<br>

üèÜ Resultado del plan de 12 meses: Al completar este plan, el CISO habr√°: (1) cerrado las brechas cr√≠ticas bajo la Ley 25.326 vigente, (2) anticipado el 80% de los requisitos de la reforma argentina 2025 antes de su aprobaci√≥n, (3) cumplido con EU AI Act para sistemas de alto riesgo antes del deadline de agosto 2026, y (4) establecido la base para ISO 42001 como ventaja competitiva. La gobernanza de IA deja de ser un costo regulatorio y se convierte en un diferenciador de mercado.

<br>

## 11.6 REFERENCIAS (R271‚ÄìR300)

<br>

Regulaci√≥n de IA y Datos Personales en Argentina:

R271. AAIP, 'Proyecto de Ley de Protecci√≥n de Datos Personales', argentina.gob.ar, 2025. Reforma de la Ley 25.326 propuesta por la autoridad de aplicaci√≥n. Perdi√≥ estado parlamentario en 2024.

R272. IAPP, 'Novedades legislativas en Argentina sobre protecci√≥n de datos personales e inteligencia artificial', 2025. Proyectos Carro y Do√±ate: reforma de Ley 25.326 con alineaci√≥n GDPR/LGPD. Novedad: datos biom√©tricos como sensibles, EIMPD, sandbox regulatorio, plazo de adecuaci√≥n 6 meses.

R273. Allende & Brea, 'Iniciativas legislativas y normativa sobre IA en Am√©rica Latina', marzo 2025. Proyecto S-0071/2025: sistema de riesgo en 4 niveles, Registro Nacional de Sistemas de IA, prohibici√≥n vigilancia biom√©trica masiva.

R274. DataG√©nero, 'En Argentina ¬øse busca regular la Inteligencia Artificial?', febrero 2025. An√°lisis de 9 proyectos de ley activos. C√°mara de Diputados iniciando reuniones informativas.

R275. UTDT/CEPE & GIDE, 'AI Regulatory Frameworks: Emerging Trends in Argentina's Legislative Agenda', 2025. Working paper sobre tendencias legislativas de IA en Argentina.

R276. InfoProtecci√≥n, 'Argentina: Ley 25.326 y reformas necesarias en ciberseguridad', septiembre 2025. El desfase de la Ley 25.326 frente a las amenazas de 2025. Riesgo de p√©rdida de estatus de adecuaci√≥n EU.

R277. White & Case, 'Foster Innovation or Mitigate Risk? AI Regulation in Latin America', 2024. Argentina busca deliberadamente un ecosistema menos regulado para atraer inversi√≥n extranjera.

R278. Abogados.com.ar, 'Perspectivas Regulatorias de IA en Nuestra Regi√≥n', 2025. An√°lisis de la EU AI Act como modelo no replicable directamente en LATAM. Enfoque sectorizado como el m√°s probable para Argentina.

<br>

Brasil y Chile ‚Äî Marcos M√°s Avanzados:

R279. Chambers & Partners, 'Artificial Intelligence 2025 ‚Äî Brazil', 2025. PL 2338/2023: aprobado Senado diciembre 2024, Comisi√≥n Especial en C√°mara de Diputados desde abril 2025. Multas: BRL 50M o 2% facturaci√≥n. ANPD como autoridad supervisora.

R280. Library of Congress / Eduardo Soares, 'Brazil: Senate Advances Discussions on Bill to Regulate AI', mayo 2025. Forwarded to Chamber of Deputies 17 marzo 2025. Special Committee of 33 members established 29 April 2025.

R281. Leonardi Advogados, 'Updates on the Artificial Intelligence Bill (PL 2338/2023)', mayo 2025. Estado del proceso legislativo en la C√°mara.

R282. SIDI, 'PL 2338/2023: the Impacts of Regulating Artificial Intelligence in Brazil', octubre 2025. Principios: transparencia, seguridad, protecci√≥n de datos, accountability, clasificaci√≥n por riesgo.

R283. AI Governance Brazil / Nemko, 'Navigating Policies & Compliance', 2025. Tres categor√≠as de riesgo bajo el proyecto. Sandboxes para fintech, healthtech, smart cities. Armonizaci√≥n regional con Chile, Argentina, M√©xico.

R284. CMS Expert Guides, 'AI Laws and Regulations in Chile', febrero 2026. Proyecto aprobado por C√°mara de Diputados el 13 octubre 2025. Actualmente en el Senado. Sin fecha fija de promulgaci√≥n. Ley Marco de Ciberseguridad 21.663 vigente: crea ANCI.

R285. Compliance & Risks, 'Latin America AI Legislative Initiatives', septiembre 2025. Chile: segunda lectura en Senado. Brasil: Comisi√≥n Especial en C√°mara. Per√∫: Ley 31814 vigente. Colombia: nuevo proyecto 2025. Panam√°: propuestas en Asamblea.

<br>

Panorama Regional y EU AI Act Extraterritorial:

R286. CEPAL/CENIA, 'ILIA 2025: Consolidated as a Policy-Design Instrument for AI in the Region', octubre 2025. 19 pa√≠ses evaluados. Pioneers: Chile, Brasil, Uruguay (>60 pts). LATAM: 14% visitas globales a IA. 3er lugar mundial en descargas GenAI.

R287. Americas Quarterly, 'Regulating AI on Latin America's Terms', julio 2025. Ventana estrecha para regular antes de convertirse en 'dumping ground' de sistemas de IA no probados. EE.UU.: pivot a desregulaci√≥n con √≥rdenes ejecutivas Trump 2025. UE: EU AI Act + CAIDA en preparaci√≥n.

R288. Bloomberg L√≠nea / Niubox, 'Las dudas que dejan los proyectos de ley sobre IA en LATAM en 2025', febrero 2025. 109 iniciativas analizadas en 8 pa√≠ses. 98 en tr√°mite. Solo 4 centradas en innovaci√≥n. LATAM: adoptora, no productora de tecnolog√≠a de IA.

R289. White & Case, 'AI Watch: Global Regulatory Tracker ‚Äî Brazil', actualizado 2025. Sin fecha esperada para pr√≥ximos desarrollos legislativos en Brasil. Multas finales sujetas a cambios en C√°mara.

R290. Future of Privacy Forum, 'AI Regulation in Latin America: Overview and Emerging Trends', 2025. Derecho a revisi√≥n humana de decisiones automatizadas: diferencias entre LGPD y propuestas regionales.

R291. Corporate Compliance Insights, '2026 Operational Guide to Cybersecurity, AI Governance & Emerging Risks', enero 2026. Compliance de IA: SEC examinations 2026 priorizan cybersecurity y IA sobre cripto. IT + Compliance: alianza estrat√©gica. AI washing como nuevo riesgo.

R292. EU AI Act ‚Äî Reglamento (UE) 2024/1689. Vigente desde agosto 2024. Pr√°cticas prohibidas: febrero 2025. Sistemas de alto riesgo (Anexo III): agosto 2026. Plena aplicaci√≥n supervisi√≥n: agosto 2027. Multas: ‚Ç¨35M o 7% facturaci√≥n global para infracciones graves.

R293. Decisi√≥n de la Comisi√≥n Europea 2003/490/CE. Argentina: reconocida como pa√≠s con nivel adecuado de protecci√≥n de datos por la UE. Facilita transferencias de datos entre Argentina y pa√≠ses de la UE sin mecanismos adicionales.

R294. NIST AI RMF (AI 100-1), enero 2023. Cuatro funciones: Govern, Map, Measure, Manage. Marco de referencia internacional para gesti√≥n de riesgos de IA. Adoptado como base por m√∫ltiples reguladores LATAM.

R295. ISO/IEC 42001:2023. International Standard for AI Management Systems. Requisito de facto emergente en licitaciones enterprise globales. Alineado con EU AI Act, NIST AI RMF y marcos LATAM emergentes.

<br>

Seguridad y Regulaci√≥n Sectorial en LATAM:

R296. Center for Cybersecurity Policy and Law, 'AI Governance in Latin America', 2025. IA como vector de ataque y defensa en ciberseguridad. Gobiernos de LATAM: equilibrio entre innovaci√≥n y regulaci√≥n responsable.

R297. SentinelOne, 'AI Security Standards: Key Frameworks for 2026', febrero 2026. NIST AI RMF, OWASP LLM Top-10, MITRE ATLAS, Google SAIF: los 5 marcos esenciales para el CISO. Compliance chaos: demasiados marcos convergentes.

R298. Global Solutions Journal, 'AI Governance in Latin America', 2025. An√°lisis de brechas entre gobernanza de IA y capacidad institucional regional.

R299. ANPD Brasil, 'Pilot Regulatory Sandbox for AI and Data Protection', junio 2025. Activo hasta diciembre 2026. Selecci√≥n de proyectos piloto anunciada desde octubre 2025.

R300. White & Case, 'Latin America Focus 2024: AI Regulation'. An√°lisis comparativo: Brasil, M√©xico, Chile y Argentina. Argentina: enfoque deliberadamente menos restrictivo para atraer IED en IA.

<br>
