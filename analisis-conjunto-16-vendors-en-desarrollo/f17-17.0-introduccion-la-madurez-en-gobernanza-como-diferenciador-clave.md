---
icon: check
---

# F17 - 17.0 INTRODUCCI√ìN: LA MADUREZ EN GOBERNANZA COMO DIFERENCIADOR CLAVE





**¬ß15.0 Introducci√≥n** ‚Äî La tensi√≥n estructural entre IA y privacidad: tabla comparativa de 6 dimensiones mostrando los riesgos sin privacy engineering vs. los controles t√©cnicos que lo mitigan (training, contexto LLM, corpus RAG, fine-tuning, outputs, logs). El marco regulatorio que lo obliga: GDPR Art. 25, EU AI Act Art. 10, Reforma 25.326 Argentina.

**¬ß15.1 Privacy-by-Design para IA** ‚Äî Adaptaci√≥n de los 7 principios de Cavoukian (1996, elevados a ley en GDPR) al contexto espec√≠fico de LLMs, RAG y agentes. El principio proactivo aplicado al DPIA de IA antes del deployment; el de configuraci√≥n predeterminada aplicado a Zero Data Retention y contexto m√≠nimo en Copilot; el de funcionalidad total respondiendo al mito de que privacidad = peor modelo.

**¬ß15.2 T√©cnicas de Privacy Preservation** ‚Äî Differential Privacy con detail: el par√°metro epsilon y sus valores en producci√≥n enterprise (Œµ=8.65 alineado con ISO/IEC 27559 y NIST SP 800-226), DP-SGD, las librer√≠as Opacus y TF Privacy, el trade-off privacidad-utilidad con datos cuantitativos. Federated Learning: los 4 tipos (horizontal, vertical, cross-device, FL+DP combinado) con casos reales 2025 incluyendo Zurich+Orange (30% mejora) y KAIST. Homomorphic Encryption y SMPC: estado 2025, overhead, Azure Confidential Computing como alternativa pr√°ctica.

**¬ß15.3 Anonimizaci√≥n, Pseudonimizaci√≥n y Synthetic Data** ‚Äî El continuo legal-t√©cnico entre las tres t√©cnicas con sus implicaciones bajo GDPR/Ley 25.326. El problema de los quasi-identifiers (Sweeney 1997: c√≥digo postal + g√©nero + fecha de nacimiento re-identifica al 87%). Machine Unlearning como respuesta t√©cnica al derecho al olvido: reentrenamiento exacto (viable para modelos propios peque√±os), approximate unlearning (investigaci√≥n activa), y la postura pr√°ctica de compliance cuando el unlearning exacto no es t√©cnicamente posible. Microsoft Presidio como herramienta operacional para anonimizaci√≥n de PII en corpus.

**¬ß15.4 Data Minimization en LLM y RAG** ‚Äî Las 5 dimensiones de minimizaci√≥n t√©cnica: contexto del LLM (purging autom√°tico, filtros de PII, separaci√≥n por clasificaci√≥n), corpus RAG (pol√≠ticas de retenci√≥n, exclusi√≥n de categor√≠as, auditor√≠a de permisos SharePoint), logs de interacciones (m√°ximo 90 d√≠as para contenido completo), outputs del LLM (Purview DLP, sensitivity labels en respuestas), y embeddings en vector database (access control, no indexar datos ultra-sensibles, encriptaci√≥n at-rest).

**¬ß15.5 Microsoft Purview para Privacidad de IA** ‚Äî Mapa completo de 8 capacidades Purview con descripci√≥n, relevancia para privacidad de IA, y estado de disponibilidad: DSPM for AI, Sensitivity Labels (MIP), DLP para Copilot, Audit Log, Insider Risk Management for AI, Compliance Manager (con templates EU AI Act y GDPR), Data Lifecycle Management, y Data Risk Assessments. El Copilot Oversharing Problem: el 8.5% de prompts enterprise expone datos sensibles, y el l√≠mite de Purview (controla acceso, no inferencia sem√°ntica).

**¬ß15.6 DPIA para Sistemas de IA** ‚Äî Cu√°ndo es obligatorio (6 criterios GDPR con ejemplos en contexto M365). El proceso completo de 8 pasos adaptado a sistemas de IA con outputs y evidencias para cada paso: descripci√≥n, necesidad/proporcionalidad, riesgos espec√≠ficos de IA (memorizaci√≥n, inferencias indeseadas, sesgo, reidentificaci√≥n, derecho al olvido inviable), controles existentes, plan de mitigaci√≥n, consulta con DPO, revisi√≥n continua, documentaci√≥n.

**¬ß15.7 Plan para CISO** ‚Äî Seis acciones concretas para los primeros 90 d√≠as: activar DSPM for AI, completar etiquetado MIP, implementar DLP en Copilot, ejecutar DPIAs para casos de alto riesgo, configurar retenci√≥n de logs, e inventariar todos los sistemas de IA. Programa maduro para a√±o 1 y 2027: privacy review como gate de deployment, auditor√≠a anual, capacitaci√≥n de 20,000 usuarios Copilot, Presidio para corpus RAG, proceso de ejercicio de derechos GDPR, y PETs para modelos propios.



## 17.0 INTRODUCCI√ìN: LA MADUREZ EN GOBERNANZA COMO DIFERENCIADOR CLAVE

<br>

La investigaci√≥n de Cloud Security Alliance publicada en diciembre de 2025 es contundente: la madurez de gobernanza es el factor m√°s determinante que separa las organizaciones que se sienten preparadas para asegurar la IA de las que no. Solo el 25% de las organizaciones tiene gobernanza de seguridad de IA comprensiva. El 75% restante opera con gu√≠as parciales o pol√≠ticas a√∫n en desarrollo. Esta brecha se traduce directamente en diferencias de alineaci√≥n entre Boards, equipos ejecutivos y equipos de seguridad, y en diferencias de confianza para usar la IA en flujos de trabajo operacionales cr√≠ticos.

El presente informe completa el proyecto de 17 Fases con la s√≠ntesis operacional: el Modelo de Madurez en Gobernanza de IA que permite al CISO (1) saber d√≥nde est√° su organizaci√≥n hoy, (2) saber hacia d√≥nde debe evolucionar, y (3) comunicar ese estado y progreso al Board con KPIs ejecutivos comprensibles. Es el marco que integra los contenidos de las 16 Fases anteriores en una hoja de ruta accionable.

<br>

| ESTADO DE LA INDUSTRIA 2025-2026                                                                                                                             | IMPLICACI√ìN PARA EL CISO                                                                                                                                                                                  |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Solo el 25% de organizaciones tiene gobernanza de seguridad de IA comprensiva (CSA, diciembre 2025)                                                          | Las primeras organizaciones en alcanzar madurez L3-L4 tendr√°n ventaja competitiva regulatoria y de cliente significativa frente al 75% que reci√©n comienza.                                               |
| El 75% tiene pol√≠ticas de uso de IA, pero solo el 36% tiene un framework formal de gobernanza (Pacific AI Survey 2025)                                       | Tener una pol√≠tica de uso aceptable de IA no es suficiente. Sin roles, controles, monitoreo y enforcement estructurados, la pol√≠tica es papel mojado.                                                     |
| El 62% de Boards discute IA regularmente, pero solo el 27% ha formalizado la gobernanza de IA en su charter (NACD 2025)                                      | El CISO debe proveer el lenguaje y los KPIs que permitan al Board pasar de 'discusi√≥n de IA' a 'gobernanza de IA en el charter'.                                                                          |
| El 44% de ejecutivos dice que el proceso de gobernanza de IA es demasiado lento; el 58% cita sistemas desconectados como bloqueador (ModelOp 2025 Benchmark) | Gobernanza madura no significa gobernanza lenta. El objetivo es reducir el time-to-production de 6-18 meses a 2-4 meses para casos de bajo riesgo, mientras se refuerza el rigor para los de alto riesgo. |
| McKinsey 2025: el tracking de KPIs de IA es infrecuente, a pesar de ser el factor que m√°s se correlaciona con impacto en compliance y negocio a largo plazo  | Sin m√©tricas no hay accountability. Sin accountability no hay gobernanza real. La Fase 17 pone los KPIs en el centro del modelo de madurez.                                                               |
| El 80% de empresas tiene 50+ casos de uso GenAI en pipeline; la mayor√≠a tiene muy pocos en producci√≥n (ModelOp 2025)                                         | La brecha entre ideaci√≥n y producci√≥n se cierra con gobernanza estructurada, no con m√°s pilotos. La gobernanza es el habilitador de la escala de IA, no su freno.                                         |

<br>

## 17.1 EL MODELO AIGSM ‚Äî AI GOVERNANCE SECURITY MATURITY (5 NIVELES)

<br>

El modelo AIGSM (AI Governance Security Maturity) que se presenta a continuaci√≥n sintetiza los frameworks de referencia del sector ‚Äî ISO 42001, NIST AI RMF, EU AI Act, y la investigaci√≥n de madurez de CSA, Gartner y McKinsey ‚Äî en un modelo de 5 niveles dise√±ado espec√≠ficamente para el CISO con ecosistema Microsoft. Cada nivel describe el estado en 6 dimensiones: Pol√≠tica y Framework, Inventario y Clasificaci√≥n de Riesgos, Controles T√©cnicos, Privacy & Seguridad, M√©tricas y Reporting, y Cultura Organizacional. El CISO puede autoevaluar su posici√≥n actual y planificar la evoluci√≥n.

<br>

| NIVEL 1  ‚Äî  REACTIVO  /  AD-HOC |                                                                                                                                                   |                                                                                                                        |
| ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------- |
| DIMENSI√ìN                       | ESTADO T√çPICO                                                                                                                                     | SE√ëALES DE ALERTA                                                                                                      |
| Pol√≠tica y Framework            | Sin pol√≠tica de uso de IA. Cada equipo adopta herramientas de IA a su criterio. El CISO conoce el problema pero no tiene mandato formal.          | Empleados usando ChatGPT/Copilot con datos de clientes sin pol√≠tica de uso aceptable ni conciencia de los riesgos.     |
| Inventario de IA                | Sin inventario de sistemas de IA en uso. Existe 'Shadow AI' ‚Äî herramientas de IA no aprobadas que la organizaci√≥n no conoce.                      | El DSPM for AI detecta decenas de apps de IA activas en la red que IT nunca aprob√≥.                                    |
| Controles T√©cnicos              | Controles generales de seguridad (MFA, DLP b√°sico) sin configuraci√≥n espec√≠fica para IA. Copilot activo sin DLP en prompts ni sensitivity labels. | DSPM for AI muestra alto % de prompts con PII. Sin policy hits en DLP de Copilot porque no hay pol√≠ticas configuradas. |
| Privacy & Seguridad             | Sin DPIA para sistemas de IA. Sin proceso de red teaming. Logs de Copilot retenidos indefinidamente sin pol√≠tica.                                 | Primer incidente de privacidad con Copilot descubierto por un empleado, no por un control.                             |
| M√©tricas y Reporting            | Sin KPIs de gobernanza de IA. El Board no recibe informaci√≥n sobre riesgos de IA. La percepci√≥n de riesgo es principalmente anecd√≥tica.           | El CISO no puede responder cu√°ntos sistemas de IA tiene la organizaci√≥n ni cu√°les son sus riesgos m√°s cr√≠ticos.        |
| Cultura                         | Entusiasmo por la IA sin conciencia de riesgos. Los campeones de IA del negocio avanzaron sin involucramiento de seguridad.                       | El CIO anunci√≥ el despliegue de Copilot sin un Privacy Impact Assessment ni un proceso de training de usuarios.        |

<br>

| NIVEL 2  ‚Äî  EMERGENTE  /  POL√çTICAS INICIALES |                                                                                                                                                                                         |                                                                                                                          |
| --------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| DIMENSI√ìN                                     | ESTADO T√çPICO                                                                                                                                                                           | PR√ìXIMOS PASOS                                                                                                           |
| Pol√≠tica y Framework                          | Pol√≠tica de uso aceptable de IA documentada y aprobada. Proceso de solicitud para nuevas herramientas de IA. Sin framework formal de gobernanza (ISO 42001 o NIST AI RMF) adoptado a√∫n. | Adoptar NIST AI RMF como framework de referencia (gratuito, flexible). Iniciar gap analysis para ISO 42001.              |
| Inventario de IA                              | Inventario inicial de sistemas de IA en producci√≥n. No es exhaustivo ‚Äî 'Shadow AI' a√∫n presente. Proceso de registro de nuevas herramientas activo.                                     | Usar DSPM for AI para descubrimiento autom√°tico de AI apps en el tenant. Establecer proceso de aprovisionamiento formal. |
| Controles T√©cnicos                            | DLP b√°sico en Copilot (bloqueo de credenciales). Sensitivity Labels aplicados parcialmente. Sin red teaming ni testing adversarial.                                                     | Activar DSPM for AI Data Risk Assessments. Ejecutar primer ejercicio de red teaming OWASP LLM01 con PyRIT.               |
| Privacy & Seguridad                           | Pol√≠tica de retenci√≥n de logs de Copilot definida. DPIAs iniciados para casos de uso de mayor riesgo. Proceso de respuesta a incidentes de IA documentado.                              | Completar DPIAs para todos los casos de uso de alto riesgo. Primer DPIA para agentes de Copilot Studio.                  |
| M√©tricas y Reporting                          | Primeras m√©tricas de IA definidas (inventario de sistemas, N¬∞ de incidentes). Reporte trimestral al CISO pero no al Board.                                                              | Dise√±ar el AI Governance Dashboard para el Board. Definir los 5-7 KPIs ejecutivos.                                       |
| Cultura                                       | Entrenamiento b√°sico en uso responsable de Copilot para usuarios. El equipo de seguridad tiene conciencia de riesgos pero no expertise espec√≠fico en IA.                                | Capacitar al equipo de seguridad en OWASP LLM Top 10. Designar AI Security Champions en cada unidad de negocio.          |

<br>

| NIVEL 3  ‚Äî  DEFINIDO  /  FRAMEWORK ESTRUCTURADO |                                                                                                                                                                                                                           |                                                                                                                                                  |
| ----------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| DIMENSI√ìN                                       | ESTADO T√çPICO                                                                                                                                                                                                             | DIFERENCIADOR                                                                                                                                    |
| Pol√≠tica y Framework                            | NIST AI RMF implementado (Govern, Map, Measure, Manage). Gap analysis contra ISO 42001 completado. Plan de certificaci√≥n ISO 42001 en ejecuci√≥n. AI Governance Committee activo con reuniones trimestrales.               | La diferencia respecto al Nivel 2: el framework no es solo un documento ‚Äî tiene roles asignados, procesos documentados y evidencia de ejecuci√≥n. |
| Inventario de IA                                | Inventario completo y actualizado de todos los sistemas de IA. Clasificaci√≥n de riesgo (alto/medio/bajo) para cada sistema. Proceso de onboarding de nuevos sistemas de IA con privacy review y threat model obligatorio. | Privacy Review Gate: ning√∫n sistema de IA va a producci√≥n sin checklist de seguridad y privacidad aprobado.                                      |
| Controles T√©cnicos                              | OWASP LLM Top 10 coverage >60% en red teaming. DLP configurado para todas las categor√≠as de PII en Copilot. Sensitivity Labels al >90% en documentos de alta sensibilidad. Kill switch documentado para agentes.          | El red teaming es parte del SDLC de IA, no un ejercicio separado anual.                                                                          |
| Privacy & Seguridad                             | DPIAs completados para todos los sistemas de alto riesgo. Proceso de Machine Unlearning/ejercicio de derechos GDPR documentado. Azure Confidential Computing evaluado para cargas de trabajo sensibles.                   | Compliance Manager muestra score de compliance EU AI Act y GDPR para todos los sistemas de IA en scope.                                          |
| M√©tricas y Reporting                            | AI Governance Dashboard activo con KPIs trimestrales al Board. ASR (Attack Success Rate) por categor√≠a OWASP LLM. Time to Remediation por severidad. Cobertura de sistemas con DPIA.                                      | El Board recibe un AI Risk Scorecard en cada sesi√≥n trimestral, an√°logo al Cyber Risk Scorecard ya establecido.                                  |
| Cultura                                         | AI Security Champions activos en cada unidad de negocio. >80% de usuarios de Copilot con capacitaci√≥n completada. El equipo de seguridad tiene al menos un especialista en AI Security.                                   | El AI Governance Committee incluye representantes del negocio, no solo de IT/Seguridad.                                                          |

<br>

| NIVEL 4  ‚Äî  GESTIONADO  /  M√âTRICAS Y CONTROL |                                                                                                                                                                                                                                  |                                                                                                                                   |
| --------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |
| DIMENSI√ìN                                     | ESTADO T√çPICO                                                                                                                                                                                                                    | LO QUE PRUEBA ESTE NIVEL                                                                                                          |
| Pol√≠tica y Framework                          | ISO 42001 certificaci√≥n obtenida o en proceso de auditor√≠a final. El AI Management System (AIMS) es parte del sistema integrado de gesti√≥n junto con ISO 27001 y GDPR. Revisi√≥n anual del AIMS con evidencia de mejora continua. | La certificaci√≥n ISO 42001 es la evidencia objetiva de madurez L4 ‚Äî es verificada por terceros, no autodeclarada.                 |
| Inventario de IA                              | Inventario en tiempo real: cambios en sistemas de IA (nuevos modelos, nuevos conectores, nuevas herramientas de agentes) son capturados autom√°ticamente. AIBOM (AI Bill of Materials) para modelos propios.                      | El AIBOM documenta el linaje completo del modelo: datos de entrenamiento, versi√≥n, controles de privacidad aplicados.             |
| Controles T√©cnicos                            | OWASP LLM Top 10 coverage >90%. Red teaming continuo integrado en CI/CD. Regression suite autom√°tico tras cada actualizaci√≥n de modelo. Azure AI Red Teaming Agent (PyRIT) ejecutando scans programados.                         | La seguridad de la IA no depende de sprints de red teaming ‚Äî est√° embedded en el pipeline de desarrollo.                          |
| Privacy & Seguridad                           | Privacy by Design es un gate obligatorio para nuevos sistemas. Differential Privacy implementada en pipelines de fine-tuning propios. Derecho al olvido con proceso documentado y tiempos de respuesta medidos.                  | El CISO puede demostrar a un regulador no solo que tiene pol√≠ticas sino c√≥mo se implementan t√©cnicamente.                         |
| M√©tricas y Reporting                          | KPIs con benchmarking externo (comparaci√≥n con industria). An√°lisis de tendencia: el Board puede ver si la postura de gobernanza de IA est√° mejorando o deterior√°ndose en el tiempo.                                             | El reporte de gobernanza de IA es comparable a√±o sobre a√±o. El Board puede preguntar '¬ømejoramos respecto al trimestre anterior?' |
| Cultura                                       | La gobernanza de IA es cultura organizacional, no compliance. Los equipos de desarrollo autom√°ticamente incluyen privacy review y threat model como parte de su proceso ‚Äî no esperan a que seguridad les recuerde.               | El indicador m√°s confiable: los desarrolladores de IA consultan al equipo de seguridad proactivamente.                            |

<br>

| NIVEL 5  ‚Äî  OPTIMIZADO  /  INNOVACI√ìN RESPONSABLE CONTINUA |                                   |
| ---------------------------------------------------------- | --------------------------------- |
| CARACTER√çSTICAS DEL NIVEL 5                                | C√ìMO DIFERENCIA A LA ORGANIZACI√ìN |
| L                                                          | a                                 |
| C                                                          | o                                 |
| A                                                          | I                                 |
| E                                                          | l                                 |

<br>

üìä D√≥nde est√° la industria hoy: CSA diciembre 2025: \~25% en Nivel 3+. \~50% en Nivel 2. \~25% en Nivel 1. Proyecci√≥n Gartner: para 2027, el 55% de empresas medianas-grandes alcanzar√° Nivel 3 por presi√≥n regulatoria del EU AI Act (obligaciones agosto 2026). El 'first mover advantage' en madurez de gobernanza de IA se cierra en 18-24 meses.

<br>

## 17.2 MARCOS DE REFERENCIA: ISO 42001, NIST AI RMF Y CONVERGENCIA REGULATORIA

<br>

El ecosistema de frameworks de gobernanza de IA madur√≥ significativamente en 2023-2025. ISO/IEC 42001 (diciembre 2023) ‚Äî el primer est√°ndar internacional para sistemas de gesti√≥n de IA ‚Äî y NIST AI RMF (enero 2023, actualizaci√≥n Generative AI Profile 2024) son los marcos de referencia principales. No son competidores ‚Äî son complementarios. ISO 42001 provee el 'qu√©' (el sistema de gesti√≥n certificable). NIST AI RMF provee el 'c√≥mo' (la metodolog√≠a de risk management flexible). El CISO que implementa ambos tiene la base para cumplir simult√°neamente con EU AI Act, GDPR y las regulaciones LATAM emergentes.

<br>

| DIMENSI√ìN                  | ISO/IEC 42001 ‚Äî AI Management System                                                                                                                                                              | NIST AI RMF ‚Äî AI Risk Management Framework                                                                                                                                                      |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Naturaleza                 | Est√°ndar internacional certificable (ISO/IEC). Certifica que el AI Management System existe, est√° implementado y es auditado.                                                                     | Framework voluntario del gobierno de EE.UU. No certificable. Gu√≠a de mejores pr√°cticas adaptable.                                                                                               |
| Estructura                 | 10 cl√°usulas (alineadas con ISO Annex SL: contexto, liderazgo, planificaci√≥n, soporte, operaci√≥n, evaluaci√≥n, mejora). Anexos de controles espec√≠ficos de IA.                                     | 4 funciones core: GOVERN (pol√≠tica, roles, cultura), MAP (identificaci√≥n de riesgos), MEASURE (evaluaci√≥n, testing), MANAGE (mitigaci√≥n, respuesta).                                            |
| Alcance                    | Cualquier organizaci√≥n que usa o provee IA. Dise√±ado para integrarse con ISO 27001 (ISMS) e ISO 27701 (PIMS).                                                                                     | Organizaciones que desarrollan, despliegan o usan IA. Especialmente relevante para organizaciones con contratos con el gobierno de EE.UU.                                                       |
| Evidencia requerida        | Documentaci√≥n del AIMS, registros de auditor√≠a interna, evidencia de revisi√≥n por direcci√≥n, no conformidades y acciones correctivas.                                                             | No requiere evidencia formal ‚Äî es un framework de gu√≠a. Pero las organizaciones que lo adoptan documentan sus implementaciones.                                                                 |
| Costo                      | Certificaci√≥n por auditor externo acreditado. 3 a√±os de vigencia con auditor√≠as de vigilancia anuales. Costo estimado para empresa mediana: USD 15,000-50,000 primer ciclo.                       | Gratuito. El costo es el tiempo de implementaci√≥n interno. Estimado: 0.5-1% del presupuesto de AI technology spend.                                                                             |
| Relaci√≥n con EU AI Act     | EU AI Act Art. 9 requiere un sistema de gesti√≥n de riesgos. ISO 42001 es reconocida como evidencia de cumplimiento del requisito. La Comisi√≥n Europea tiene una roadmap de reconocimiento formal. | NIST AI RMF 2.0 (previsto 2025) incluir√° mappings expl√≠citos al EU AI Act. Actualmente el mapping existe pero no es oficial.                                                                    |
| Mappings mutuos            | ISO 42001 Clause 6.1 (AI risk assessment) ‚Üî NIST AI RMF MAP. ISO 42001 Clause 9.1 (monitoring) ‚Üî NIST AI RMF MEASURE. ISO 42001 Clause 10 (improvement) ‚Üî NIST AI RMF MANAGE.                     | NIST AI RMF GOVERN ‚Üî ISO 42001 Clauses 4-7 (contexto, liderazgo, planificaci√≥n, soporte). NIST MEASURE ‚Üî ISO 42001 Clause 9. Red teaming es pr√°ctica core en NIST AI RMF Generative AI Profile. |
| Integraci√≥n con M365/Azure | Microsoft Purview Compliance Manager tiene template de ISO 42001. El assessment autom√°tico muestra el estado de compliance actual.                                                                | NIST AI RMF mappings disponibles en Purview Compliance Manager. El Generative AI Profile menciona expl√≠citamente red teaming y guardrails.                                                      |

<br>

Mapping con el EU AI Act: ISO 42001 Clause 9 (evaluaci√≥n del desempe√±o) cubre los requisitos del EU AI Act Art. 9 para sistemas de gesti√≥n de riesgos. ISO 42001 Annex A.6 (documentaci√≥n de sistemas de IA) cubre Art. 11 (documentaci√≥n t√©cnica). ISO 42001 Annex A.8 (operaci√≥n de sistemas de IA) cubre Art. 14 (supervisi√≥n humana). La implementaci√≥n de ISO 42001 no es un sustituto completo del EU AI Act pero reduce significativamente el gap de compliance.

<br>

## 17.3 KPIS Y M√âTRICAS: DE LA GOBERNANZA DECLARATIVA A LA MEDIBLE

<br>

McKinsey 2025 identifica el tracking de KPIs de IA como el factor que m√°s se correlaciona con impacto en compliance y negocio a largo plazo ‚Äî y se√±ala que es infrecuente. La mayor√≠a de los programas de gobernanza de IA tienen pol√≠ticas pero carecen de m√©tricas que permitan demostrar si la gobernanza funciona o no. Esta secci√≥n define el set completo de KPIs para un programa de gobernanza de IA maduro, organizados en 4 perspectivas: Seguridad y Riesgo T√©cnico, Privacidad y Compliance, Operaciones de IA, y Cultura y Capacidades.

<br>

| #                                            | KPI                                                          | F√ìRMULA / FUENTE                                                                                                                                                    | TARGET / BENCHMARK                                                                              | NIVEL MADUREZ QUE LO ACTIVA                           |
| -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- | ----------------------------------------------------- |
| PERSPECTIVA 1  ‚Äî  SEGURIDAD Y RIESGO T√âCNICO |                                                              |                                                                                                                                                                     |                                                                                                 |                                                       |
| 1                                            | Attack Success Rate (ASR) ‚Äî Prompt Injection                 | # ataques exitosos LLM01 / # total √ó 100. Fuente: PyRIT scoring engine.                                                                                             | <10% sistemas cr√≠ticos. <25% sistemas altos. Mejora ‚â•5pp por ciclo.                             | L2: primer baseline. L3+: tracking continuo           |
| 2                                            | Cobertura OWASP LLM Top 10                                   | # categor√≠as OWASP testeadas con ASR known / 10 √ó 100. Fuente: PyRIT reports.                                                                                       | >60% L3. >90% L4. 100% L5 (incluye Excessive Agency, RAG, Agentic).                             | L2: empieza. L3: objetivo 60%. L4+: >90%              |
| 3                                            | Cobertura MITRE ATLAS                                        | # t√©cnicas ATLAS relevantes testeadas / # aplicables √ó 100.                                                                                                         | >50% L3. >80% L4. >95% L5.                                                                      | L3: inventario t√©cnicas. L4+: cobertura sistem√°tica   |
| 4                                            | Tiempo de Remediaci√≥n por Severidad                          | D√≠as desde hallazgo hasta cierre verificado por severity. Fuente: ticket system.                                                                                    | Cr√≠tico: <7d. Alto: <30d. Medio: <90d. Bajo: pr√≥ximo ciclo.                                     | L2: tracking manual. L3+: KPI formal con SLA          |
| 5                                            | Tasa de Regresi√≥n en Red Teaming                             | % vulnerabilidades previamente remediadas que reaparecen. Fuente: comparaci√≥n scorecards PyRIT.                                                                     | <5% regresi√≥n. Si >10%: revisar proceso de remediaci√≥n.                                         | L3: primer tracking. L4+: benchmark trimestral        |
| PERSPECTIVA 2  ‚Äî  PRIVACIDAD Y COMPLIANCE    |                                                              |                                                                                                                                                                     |                                                                                                 |                                                       |
| 6                                            | Cobertura DPIA                                               | # sistemas IA alto riesgo con DPIA completo / # total √ó 100.                                                                                                        | 100% sistemas alto riesgo L3. 100% todos L4.                                                    | L2: DPIAs iniciados. L3: 100% alto riesgo             |
| 7                                            | Score de Compliance Purview (EU AI Act / GDPR)               | % controles implementados seg√∫n Compliance Manager template. Fuente: Microsoft Purview Compliance Manager.                                                          | >60% L3. >80% L4. >95% L5.                                                                      | L2: primer assessment. L3+: objetivo trimestral       |
| 8                                            | Tasa de Prompts con PII Detectados por DLP                   | # prompts con PII detectados / # total prompts Copilot √ó 100. Fuente: Purview DLP reports.                                                                          | <2% prompts con PII bloqueados L3. <0.5% L4 (educaci√≥n reduce). Tendencia decreciente.          | L2: primera medici√≥n. L3: target y educaci√≥n          |
| 9                                            | Cobertura Sensitivity Labels en Documentos Cr√≠ticos          | # documentos clasificados alto/confidencial con label / # total √ó 100. Fuente: Purview Information Protection.                                                      | >90% L3. >99% L4 (auto-labeling activo).                                                        | L2: auditor√≠a inicial. L3+: auto-labeling             |
| 10                                           | Tiempo Respuesta Ejercicio Derechos GDPR en Sistemas IA      | D√≠as desde solicitud hasta resoluci√≥n documentada. Fuente: registro DPO.                                                                                            | <30 d√≠as (GDPR obligatorio). Objetivo: <15 d√≠as L4.                                             | L3: proceso documentado. L4: SLA medido               |
| PERSPECTIVA 3  ‚Äî  OPERACIONES DE IA          |                                                              |                                                                                                                                                                     |                                                                                                 |                                                       |
| 11                                           | Cobertura de Inventario de Sistemas IA                       | # sistemas IA registrados en inventario / # sistemas IA detectados por DSPM √ó 100.                                                                                  | >80% L2. 100% L3+.                                                                              | L2: primer inventario. Mejora continua.               |
| 12                                           | Tiempo Promedio Deployment Nuevo Sistema IA (con Governance) | D√≠as desde solicitud hasta aprobaci√≥n para producci√≥n incluyendo privacy review + threat model + red team b√°sico.                                                   | <60 d√≠as L3. <30 d√≠as L4 (proceso optimizado). <10 d√≠as L5 (governance as code para low-risk).  | L3: gate de deployment activo. L4: proceso optimizado |
| 13                                           | Tasa de Incidentes de Seguridad de IA (AISecIR)              | # incidentes de seguridad relacionados con sistemas de IA por trimestre. Categorizar: exfiltraci√≥n datos, prompt injection exitosa, agente actuando fuera de scope. | Baseline trimestre 1 ‚Üí tendencia decreciente. 0 incidentes Cr√≠ticos L4.                         | L2: tracking iniciado. L3+: benchmark                 |
| 14                                           | ROI del Programa de Gobernanza de IA                         | (Costo incidentes evitados + valor de contratos ganados por certificaci√≥n ISO 42001) / Costo del programa √ó 100. Fuente: estimaci√≥n actuarial + ventas.             | >200% ROI L3 (referencia: incidente financiero USD 3M evitado vs. costo programa USD 150K/a√±o). | L3+: c√°lculo formal presentable al Board              |
| PERSPECTIVA 4  ‚Äî  CULTURA Y CAPACIDADES      |                                                              |                                                                                                                                                                     |                                                                                                 |                                                       |
| 15                                           | Cobertura de Training en AI Governance                       | # empleados con rol IA (usuarios Copilot, desarrolladores, RRHH, finanzas) con training completado / # total √ó 100.                                                 | >80% usuarios Copilot L3. >90% L4. 100% L5.                                                     | L2: primeros m√≥dulos. L3: target 80%                  |
| 16                                           | AI Security Champions Activos                                | # unidades de negocio con AI Security Champion designado y activo / # total unidades de negocio.                                                                    | 1 Champion por unidad de negocio L3. Champions con certificaci√≥n AI Security L4.                | L3: programa Champions iniciado                       |
| 17                                           | AI Governance Committee ‚Äî Asistencia y Decisiones            | # decisiones documentadas por el AI Governance Committee por trimestre. % asistencia de miembros.                                                                   | ‚â•4 decisiones formales/trimestre. >80% asistencia.                                              | L2: Committee formado. L3: funcionamiento regular     |

<br>

## 17.4 AI GOVERNANCE DASHBOARD: REPORTING AL BOARD Y AL AI GOVERNANCE COMMITTEE

<br>

El AI Governance Dashboard es el artefacto que traduce el programa de gobernanza de IA en un lenguaje comprensible para el Board y el AI Governance Committee. No es un informe t√©cnico ‚Äî es un instrumento de gesti√≥n ejecutiva que responde tres preguntas: (1) ¬øCu√°l es nuestra postura de gobernanza de IA hoy? (2) ¬øEstamos mejorando? (3) ¬øQu√© riesgo residual existe que el Board debe conocer?

<br>

### 17.4.1 Scorecard Ejecutivo de Gobernanza de IA ‚Äî Q1 2026 (Ejemplo)

| √ÅREA                                      | SCORE ACTUAL                           | SCORE ANTERIOR      | TENDENCIA | ACCI√ìN REQUERIDA                                                               |
| ----------------------------------------- | -------------------------------------- | ------------------- | --------- | ------------------------------------------------------------------------------ |
| Madurez General AIGSM                     | Nivel 3 / 5                            | Nivel 2 / 5         | ‚Üë +1      | Completar ISO 42001 gap analysis (Q2 2026)                                     |
| Inventario Sistemas IA                    | 94% cobertura                          | 78% cobertura       | ‚Üë +16pp   | Incorporar 3 agentes Copilot Studio pendientes                                 |
| Red Teaming OWASP Coverage                | 68% (6.8/10 categor√≠as)                | 45%                 | ‚Üë +23pp   | Cubrir LLM08 (RAG) y LLM10 (Unbounded Consumption) en Q2                       |
| Sensitivity Labels Coverage               | 91% docs confidencial                  | 72%                 | ‚Üë +19pp   | Completar auto-labeling de OneDrive hist√≥rico                                  |
| DLPs Copilot Activos                      | 7 de 9 pol√≠ticas clave                 | 4 de 9              | ‚Üë +3      | Implementar DLP para datos de n√≥mina y presupuesto                             |
| DPIAs Completados                         | 100% alto riesgo, 60% medio            | 80% alto, 30% medio | ‚Üë         | Completar DPIAs para 4 agentes Copilot Studio                                  |
| Compliance Manager Score ‚Äî EU AI Act      | 68% / 100                              | 45%                 | ‚Üë +23pp   | Principales gaps: Annex III risk classification, technical documentation       |
| Training AI Governance (usuarios Copilot) | 84% completado                         | 52%                 | ‚Üë +32pp   | Foco en 16% restante: usuarios nuevos en √∫ltimos 90 d√≠as                       |
| Incidentes de Seguridad de IA (trimestre) | 2 incidentes (1 medio, 1 bajo)         | 4 incidentes        | ‚Üë mejora  | Ambos incidentes con RCA completado. 0 cr√≠ticos.                               |
| ROI del Programa (estimado acumulado)     | 230% (USD 345K valor / USD 150K costo) | 180%                | ‚Üë +50pp   | Comunicar al Board: 2 contratos de clientes que requirieron ISO 42001 evidence |

<br>

### 17.4.2 Los 5 Riesgos de IA que el Board debe conocer ‚Äî Q1 2026

| P | RIESGO                                                                                                | ESTADO DE MITIGACI√ìN                                                                                                                  | IMPACTO POTENCIAL                                                                                                           | SEVERIDAD |
| - | ----------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------- | --------- |
| 1 | Agente HR Copilot Studio con acceso excesivo a datos de n√≥mina (ASR 35% en red team Q4 2025)          | Remediaci√≥n en curso: reducci√≥n de scope de herramientas. Human-in-the-loop activado para acciones write. Retest programado semana 8. | Exfiltraci√≥n de datos salariales de 20,000 empleados. Impacto regulatorio (GDPR) + reputacional estimado: USD 2-5M.         | ALTO      |
| 2 | Compliance EU AI Act: documentaci√≥n t√©cnica de sistemas de alto riesgo incompleta                     | Plan de remediaci√≥n en ejecuci√≥n. Deadline agosto 2026. 68% completado. Responsable: DPO + CTO.                                       | Multa m√°xima EU AI Act: 3% global annual turnover para incumplimiento de Art. 9-15. Estimaci√≥n para organizaci√≥n: EUR 1-3M. | ALTO      |
| 3 | Indirect Prompt Injection: documentos de proveedores externos procesados por Copilot sin sanitizaci√≥n | Guardrail de validaci√≥n de documentos externos en dise√±o. ETA: Q2 2026. Pendiente presupuesto aprobaci√≥n.                             | Compromiso de sesi√≥n Copilot de usuarios con acceso a datos financieros y RRHH.                                             | MEDIO     |
| 4 | Shadow AI: 23 aplicaciones de IA no aprobadas detectadas por DSPM for AI                              | 12 bloqueadas. 11 en proceso de evaluaci√≥n. Policy de bloqueo por defecto implementada para apps no aprobadas.                        | Fuga de datos corporativos a servicios de IA de terceros sin contratos de procesamiento de datos.                           | MEDIO     |
| 5 | Derecho al Olvido t√©cnico: sin capacidad de Machine Unlearning en modelos base de proveedores         | Postura documentada: para modelos de terceros, el derecho al olvido se ejerce en el corpus RAG. Comunicaci√≥n a DPO y asesor√≠a legal.  | Riesgo regulatorio si un titular GDPR ejerce derecho al olvido sobre datos que el LLM memoriz√≥ durante entrenamiento.       | MEDIO     |

<br>

## 17.5 HOJA DE RUTA 2026-2028 PARA EL CISO: DE NIVEL 2 A NIVEL 4

<br>

La hoja de ruta que sigue parte de la postura realista de una organizaci√≥n CISO con 20,000+ licencias M365 E5 y Copilot activo que ha completado los primeros pasos de gobernanza (Nivel 2). El objetivo es Nivel 4 al cierre de 2028, con el hito de certificaci√≥n ISO 42001 en el segundo semestre de 2027. Los plazos son conservadores ‚Äî organizaciones con m√°s recursos o mayor urgencia regulatoria pueden acelerar significativamente.

<br>

| PER√çODO                 | OBJETIVO DE MADUREZ                                                                                                           | INICIATIVAS CLAVE                                                                                                                                                                                                                                                                                                                                                  | HITOS VERIFICABLES                                                                                                                      |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------- |
| Q1-Q2 2026(Nivel 2‚Üí2.5) | Completar el baseline de gobernanza: inventario exhaustivo, controles b√°sicos activos, primeros KPIs medibles                 | 1. Inventario completo de sistemas IA (DSPM for AI). 2. DPIAs para todos los sistemas de alto riesgo. 3. DLP Copilot configurado categor√≠as principales. 4. Red team OWASP LLM01 y LLM06 baseline (PyRIT). 5. AI Governance Committee: primera reuni√≥n formal con KPIs.                                                                                            | DSPM for AI 100% inventario. 5 DPIAs completados. Primer AI Risk Scorecard al Board Q2 2026. ASR baseline documentado.                  |
| Q3-Q4 2026(Nivel 2.5‚Üí3) | Alcanzar Nivel 3: NIST AI RMF implementado, EU AI Act compliance documentada, privacy gate para deployments activo            | 6. Adoptar NIST AI RMF como framework formal (gap assessment + plan). 7. Compliance Manager EU AI Act: plan de remediaci√≥n de gaps antes de agosto 2026 (deadline aplicaci√≥n). 8. Privacy Review Gate: proceso de onboarding de nuevos sistemas IA con checklist obligatorio. 9. Capacitaci√≥n 80%+ usuarios Copilot. 10. Red team OWASP LLM Top 10 cobertura >60%. | NIST AI RMF adoptado formalmente. Compliance EU AI Act >70%. Privacy Gate activo. Training >80%. Declaraci√≥n Nivel 3 al Board Q4 2026.  |
| Q1-Q2 2027(Nivel 3‚Üí3.5) | Pre-certificaci√≥n ISO 42001: documentaci√≥n del AIMS completa, auditor√≠a interna, gap analysis formal con auditor externo      | 11. Contratar auditor externo acreditado para pre-assessment ISO 42001. 12. Completar documentaci√≥n de todos los clauses ISO 42001. 13. Ejecutar auditor√≠a interna del AIMS. 14. Cerrar no conformidades identificadas en pre-assessment. 15. Red team integrado en CI/CD para nuevos agentes Copilot Studio.                                                      | Pre-assessment ISO 42001 completado. No conformidades cerradas. AIMS documentado seg√∫n todos los clauses.                               |
| Q3-Q4 2027(Nivel 3.5‚Üí4) | Certificaci√≥n ISO 42001 obtenida. Nivel 4 alcanzado: AIMS certificado, red teaming en CI/CD, AIBOM para modelos propios       | 16. Auditor√≠a de certificaci√≥n ISO 42001 (Stage 1 + Stage 2). 17. AIBOM implementado para modelos fine-tuned propios. 18. Differential Privacy en pipeline de fine-tuning (si aplica). 19. Benchmark de KPIs contra industria. 20. ROI del programa documentado para presentaci√≥n al Board.                                                                        | Certificaci√≥n ISO 42001 obtenida. Declaraci√≥n Nivel 4 al Board Q4 2027. AI Governance Report anual publicado internamente.              |
| 2028(Nivel 4‚Üí5)         | Optimizaci√≥n: governance as code, contribuci√≥n a industria, Board con expertise en IA, AI governance como ventaja competitiva | 21. Governance as Code: controles de gobernanza en pipelines CI/CD (pruebas autom√°ticas de privacidad, bias, red team b√°sico). 22. Publicar AI Governance Framework propio (o contribuir al ecosistema LATAM). 23. Programa de certificaci√≥n AI Security para el equipo de seguridad. 24. Propuesta al CEO para incorporar expertise de IA en Board de Directores. | Governance as Code activo para sistemas IA de bajo-medio riesgo. AI Security certified team. Propuesta de AI Board Director presentada. |

<br>

‚ö° Acelerador clave: La brecha entre organizaciones en Nivel 2 y Nivel 3 normalmente se cierra en 18-24 meses con recursos internos normales. Se puede comprimir a 9-12 meses con: (1) un project manager dedicado al programa de gobernanza de IA, (2) uso de Purview Compliance Manager para tracking autom√°tico del estado de controles, y (3) adopci√≥n de PyRIT con Azure AI Red Teaming Agent (elimina semanas de setup manual). El costo incremental del programa de gobernanza de IA sobre el stack M365 E5 ya licenciado es principalmente tiempo del equipo, no licencias adicionales.

<br>

## 17.6 S√çNTESIS EJECUTIVA DEL PROYECTO: 17 FASES, 450 REFERENCIAS, ACCI√ìN

<br>

El proyecto ha recorrido 17 Fases que cubren el ciclo completo del due diligence, gobernanza, seguridad y compliance de IA enterprise para el CISO de 2026. Esta secci√≥n sintetiza los hallazgos principales en tres capas: los mensajes ejecutivos para el Board, los principios t√©cnicos para el equipo de seguridad, y las acciones inmediatas m√°s cr√≠ticas.

<br>

### 17.6.1 Los 10 Mensajes Ejecutivos del Proyecto

| #  | MENSAJE                                                                                                                                                                                                         | EVIDENCIA / DATO DE APOYO                                                                                                                                                                                                                                                                                                   |
| -- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1  | La IA no es un riesgo a gestionar m√°s adelante ‚Äî es un riesgo activo hoy que requiere gobernanza estructurada en 2026.                                                                                          | El 8.5% de prompts Copilot en empresas exponen datos sensibles (Knostic 2025). El 35% de incidentes de seguridad de IA son causados por prompts simples (Adversa AI 2025). EU AI Act: obligaciones de sistemas alto riesgo desde agosto 2026.                                                                               |
| 2  | La gobernanza de IA madura es un habilitador de velocidad, no un freno a la innovaci√≥n.                                                                                                                         | Las empresas en Nivel 3-4 de madurez despliegan sistemas de IA en 2-4 meses; las de Nivel 1-2 tardan 6-18 meses por falta de procesos claros (ModelOp 2025). La gobernanza elimina fricci√≥n porque los equipos saben las reglas.                                                                                            |
| 3  | Copilot con 20,000 usuarios es la superficie de ataque de IA m√°s cr√≠tica de la organizaci√≥n ‚Äî y es tambi√©n el activo de productividad m√°s valioso.                                                              | El riesgo no est√° en Copilot en s√≠, sino en la combinaci√≥n de: (a) datos sin etiquetar + (b) prompts sin DLP + (c) agentes con permisos excesivos. Los tres son controlables con el stack M365 E5 ya licenciado.                                                                                                            |
| 4  | ISO 42001 es la certificaci√≥n de gobernanza de IA que el mercado comenzar√° a requerir en contratos a partir de 2026-2027, an√°loga a lo que fue ISO 27001 en 2010-2015.                                          | Compliance Manager de Purview ya tiene el template. El camino Nivel 2 ‚Üí Certificaci√≥n ISO 42001 es de 12-18 meses con esfuerzo sostenido. Las organizaciones que empiecen en 2026 estar√°n certificadas en 2027-2028 cuando el mercado lo exija.                                                                             |
| 5  | El EU AI Act no es solo una regulaci√≥n europea ‚Äî afecta a cualquier organizaci√≥n que usa sistemas de IA que procesan datos de ciudadanos europeos o que exporta servicios de IA al mercado europeo.             | Las obligaciones m√°s relevantes para el CISO: Art. 9 (sistema de gesti√≥n de riesgos), Art. 10 (gobernanza de datos), Art. 13 (transparencia), Art. 14 (supervisi√≥n humana). Plazo de cumplimiento sistemas de alto riesgo: agosto 2026.                                                                                     |
| 6  | El riesgo del proveedor de IA (vendor risk) no termina en el contrato ‚Äî incluye las pr√°cticas de entrenamiento, las cl√°usulas de ZDR, la retenci√≥n de logs y el comportamiento bajo auditor√≠a regulatoria.      | Las Fases 5-6 del proyecto (due diligence sectorial y contratos enterprise) proveen el framework para evaluar a los 16 proveedores. Los 5 criterios m√°s cr√≠ticos: ZDR disponible, base legal de entrenamiento documentada, incidentes de seguridad reportados, cl√°usulas de subprocesamiento y certificaciones de terceros. |
| 7  | La privacidad de IA no se resuelve solo con contratos y pol√≠ticas ‚Äî requiere controles t√©cnicos embebidos en el dise√±o: Differential Privacy, Data Minimization en RAG, DLP en outputs, y Privacy Review gates. | Un 8.5% de prompts con datos sensibles es el benchmark actual sin controles t√©cnicos de privacidad. Las organizaciones con Privacy-by-Design t√©cnico documentan reducciones al 1-2% tras educaci√≥n y DLP activo.                                                                                                            |
| 8  | El red teaming de IA no es opcional ‚Äî es el mecanismo de validaci√≥n que confirma que los controles de seguridad funcionan contra amenazas reales, no solo contra amenazas te√≥ricas.                             | UK AISI/Gray Swan 2025: 1.8M ataques contra 22 modelos frontier ‚Äî todos fallaron alg√∫n ataque. PyRIT integrado en Azure AI Foundry elimina la mayor parte de la barrera de entrada para el CISO con ecosistema Microsoft.                                                                                                   |
| 9  | El horizonte 2030 muestra una IA radicalmente m√°s aut√≥noma y un entorno regulatorio significativamente m√°s denso. La gobernanza que se construye hoy debe ser lo suficientemente robusta para escalar.          | Post-Quantum Cryptography: NIST public√≥ est√°ndares PQC en 2024. La migraci√≥n cripto debe planificarse para sistemas de IA con datos de vida larga. Sistemas de IA aut√≥nomos (Agentic AI) requerir√°n controles de identidad y supervisi√≥n que MTRA los propietarios de hoy deben dise√±ar.                                    |
| 10 | La gobernanza de IA es trabajo del CISO, pero no puede ser responsabilidad exclusiva del CISO. Requiere ownership compartido entre Seguridad, Legal/DPO, Negocio y la Direcci√≥n.                                | El AI Governance Committee no es un √≥rgano t√©cnico ‚Äî es un √≥rgano de gobierno que toma decisiones de riesgo. El CISO aporta la expertise t√©cnica. El Board aporta el mandato. El negocio aporta el contexto de valor y riesgo operacional.                                                                                  |

<br>

### 17.6.2 S√≠ntesis de las 17 Fases ‚Äî Mapa del Proyecto

| FASE  | T√çTULO                                        | CONTRIBUCI√ìN CLAVE                                                                                                                                                            | ARTEFACTO PRINCIPAL                                                       |
| ----- | --------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |
| F1-F4 | Fundamentos √âticos y Filos√≥ficos              | Comparaci√≥n de 16 proveedores en filosof√≠as √©ticas (consecuencialismo, deontolog√≠a, contractualismo). Dilemas √©ticos reales. Ranking final de proveedores por madurez √©tica.  | Tabla comparativa 16 proveedores √ó 8 dimensiones √©ticas. Ranking final.   |
| F5-F6 | Due Diligence Sectorial y Contratos           | Framework de evaluaci√≥n pre-adopci√≥n para sector financiero, salud, legal y p√∫blico. An√°lisis cl√°usula por cl√°usula de contratos enterprise de los 5 principales proveedores. | Checklist de due diligence + an√°lisis contractual con cl√°usulas cr√≠ticas. |
| F7    | Gobernanza Post-Implementaci√≥n                | AI Incident Response Plan (AIRP) completo con roles, playbooks y plazos. AI Governance Committee charter. Indicadores de monitoreo continuo.                                  | AIRP + AI Governance Committee charter operacional.                       |
| F8    | S√≠ntesis Ejecutiva y Ranking Final            | Ranking final de 16 proveedores con scoring ponderado en 10 dimensiones. Recomendaciones por caso de uso y sector. Matriz de decisi√≥n para el CISO.                           | Ranking final 16 proveedores + matriz de decisi√≥n ejecutiva.              |
| F9    | ROI/TCO y Caso de Negocio                     | Framework completo de ROI para programas de seguridad y gobernanza de IA. C√°lculo de TCO para las principales plataformas. Presentaci√≥n ejecutiva para el Board.              | ROI Calculator + Business Case template para presentaci√≥n al Board.       |
| F10   | CISO IA y Defensa Aumentada                   | Microsoft Security Copilot, Defender XDR, Sentinel integrados con IA. M√©tricas de mejora de eficiencia SOC. Zero Trust + AI Security architecture.                            | Gu√≠a operacional CISO para usar IA en defensa con m√©tricas de impacto.    |
| F11   | Panorama Regulatorio LATAM                    | EU AI Act (extraterritorial para Argentina/LATAM). Reforma Ley 25.326. Regulaciones de Brasil, Chile. Compliance roadmap 12 meses.                                            | Mapa regulatorio LATAM + compliance roadmap por pa√≠s.                     |
| F12   | Horizonte Estrat√©gico 2030                    | Post-Quantum Cryptography (NIST PQC 2024), AI Agentica a escala, AI-native SOC. Roadmap de transformaci√≥n del rol del CISO 2025-2030.                                         | Roadmap estrat√©gico 2030 con iniciativas prioritarias y hitos.            |
| F13   | Red Teaming y Testing Adversarial             | OWASP LLM Top 10 2025 (10 vulnerabilidades con escenarios M365). MITRE ATLAS (15 t√°cticas). PyRIT, Garak, DeepTeam, Promptfoo. Plan de red teaming 90 d√≠as + continuo.        | Plan de red teaming M365/Copilot con herramientas y m√©tricas.             |
| F14   | Explicabilidad y Accountability Algor√≠tmica   | XAI techniques (LIME, SHAP, attention maps). Azure Responsible AI Dashboard. Accountability frameworks. Sesgo algor√≠tmico y fairness.                                         | Framework de explicabilidad + plan de implementaci√≥n Azure RAI.           |
| F15   | Privacy Engineering para IA                   | Privacy-by-Design adaptado a LLMs. Differential Privacy. Federated Learning. Synthetic Data. Machine Unlearning. Microsoft Purview para privacidad de IA. DPIA.               | Plan de privacidad de IA con controles t√©cnicos y operacionales.          |
| F16   | Explicabilidad y Accountability Algor√≠tmica 2 | Continuaci√≥n y profundizaci√≥n. Casos pr√°cticos de auditor√≠a de algoritmos. Compliance con AI Act Arts. 13-14. Herramientas de bias detection.                                 | Gu√≠a de auditor√≠a de sistemas de IA con herramientas y procesos.          |
| F17   | Modelo de Madurez en Gobernanza de IA         | AIGSM Model 5 niveles. ISO 42001 + NIST AI RMF. 17 KPIs ejecutivos. AI Governance Dashboard. Hoja de ruta 2026-2028. S√≠ntesis del proyecto.                                   | Modelo de Madurez AIGSM + Dashboard + Roadmap 2026-2028.                  |

<br>

El proyecto en cifras: 17 Fases completas. 450 referencias de alta calidad. 16 proveedores evaluados en m√∫ltiples dimensiones. Cobertura de todo el ciclo: selecci√≥n de proveedor ‚Üí contratos ‚Üí gobernanza ‚Üí seguridad ‚Üí privacidad ‚Üí regulaci√≥n ‚Üí estrategia ‚Üí madurez. El CISO que ha recorrido las 17 Fases tiene el conocimiento y los artefactos para transformar su programa de seguridad de IA de Nivel 1-2 a Nivel 4 en un horizonte de 24 meses.

<br>

## 17.7 REFERENCIAS (R421‚ÄìR450)

<br>

Estad√≠sticas de Madurez en Gobernanza de IA:

R421. Cloud Security Alliance (CSA), 'AI Security Governance Report', diciembre 2025. Publicado en Help Net Security. Solo 25% de organizaciones tiene gobernanza de seguridad de IA comprensiva. La madurez de gobernanza es el factor m√°s determinante de preparaci√≥n. CISOs supervisan presupuestos de AI security junto con l√≠deres tecnol√≥gicos y de negocio.

R422. Pacific AI, 'AI Governance Survey 2025'. 75% de organizaciones tiene pol√≠ticas de uso de IA. Solo 36% tiene un framework formal de gobernanza. La brecha pol√≠tica-framework es el desaf√≠o central de madurez en 2025-2026.

R423. National Association of Corporate Directors (NACD), '2025 Board Survey on AI'. 62% de Boards discuten IA regularmente. Solo 27% ha formalizado la gobernanza de IA en su committee charter. Los Boards est√°n en el punto de inflexi√≥n de conciencia a gobernanza estructurada.

R424. Gartner, '2025 Poll of Executive Leaders on AI Governance'. 55% de organizaciones tiene un AI board o comit√© de supervisi√≥n. Aument√≥ 20pp respecto a 2024. La adopci√≥n de comit√©s de gobernanza de IA se est√° acelerando en todos los sectores.

R425. McKinsey & Company, 'State of AI 2025'. El tracking de KPIs de IA es infrecuente pero correlaciona m√°s fuertemente con impacto en compliance y negocio a largo plazo que cualquier otra pr√°ctica. Revenue aumenta en 51-70% de business units con GenAI; el EBIT impact es m√°s modesto (15-20% de firms).

R426. ModelOp, '2025 AI Governance Benchmark Report'. 80% de enterprises tiene 50+ casos de uso GenAI en pipeline. 56% dice que tarda 6-18 meses en mover un proyecto genAI de intake a producci√≥n. 44% dice que el proceso de gobernanza es demasiado lento. 58% cita sistemas desconectados como bloqueador principal.

<br>

Modelos de Madurez y Frameworks de Gobernanza de IA:

R427. Inference.net, 'AI Governance Maturity Model: 5 Stages + Assessment Tool', febrero 2026. Los 5 niveles de madurez para AI governance: de ad-hoc a optimizado. KPIs por nivel: inventory coverage, % models with complete model cards, evaluation pass rates. Reassessment cada 6-12 meses o tras cambios regulatorios.

R428. Liminal.ai, 'Enterprise AI Governance: Complete Implementation Guide 2025'. AI Governance Committee: reuniones trimestrales con l√≠deres de Security, Risk, Legal, Compliance, Technology, Business Units. Costo programa: 0.5-1% del AI technology spend. 4-6 meses para gobernanza base; 12-24 meses para Nivel 3-4.

R429. Dataversity, 'Building a Practical Framework for AI Governance Maturity in the Enterprise', noviembre 2025. Gobernanza madura no es control r√≠gido sino agility with assurance. El framework predecible de gobernanza acelera la innovaci√≥n, no la frena.

R430. California Management Review, 'AI Governance Maturity Matrix: A Roadmap for Smarter Boards', mayo 2025. 4 etapas del Board en gobernanza de IA: inconsciente, reactivo, proactivo, transformativo. Solo 13% de S\&P 500 tiene directores con expertise en IA. Deep Knowledge Ventures: VITAL como algoritmo en el board.

R431. Deloitte, 'AI Board Governance Roadmap', 2025. Overseeing AI requires: AI fluency en el Board, entender el estado de adopci√≥n de IA de la empresa, y comprender las pol√≠ticas de AI governance. La conversaci√≥n de IA en el Board debe evolucionar de awareness a oversight estructurado.

R432. TrustCloud, '2025 CISOs Guide to AI Governance'. AI governance aligned con ISO 42001 y NIST AI RMF. Estrategias para evaluar AI risk de terceros. Streamline documentation para auditor√≠as. Best practices de Cribl, Evisort, IMO Health.

<br>

ISO 42001 y NIST AI RMF:

R433. ISO/IEC 42001:2023, 'Information Technology ‚Äî Artificial Intelligence ‚Äî Management System'. El primer est√°ndar internacional para AI Management Systems (AIMS). 10 cl√°usulas + Anexos de controles. Certifiable por terceros. Publicado diciembre 2023. iso.org/standard/42001.

R434. RSI Security Blog, 'NIST AI RMF & ISO/IEC 42001: Crosswalk for AI Compliance', diciembre 2025. A octubre 2025, ninguno es legalmente obligatorio en EE.UU. pero son estrat√©gicamente esenciales. Crosswalk: NIST AI RMF MAP ‚Üî ISO 42001 Clause 6.1 (risk assessment). NIST GOVERN ‚Üî ISO 42001 Clauses 4-7. Implementar NIST primero agiliza ISO 42001.

R435. FairNow, 'Integrating the NIST AI RMF and ISO 42001: A Practical Guide', octubre 2025. Gap analysis como primer paso cr√≠tico. KPIs atados a goals de gobernanza. ISO 42001 requiere metodolog√≠a estructurada para evaluar AI governance maturity. Las organizaciones con ISO 27001 tienen ventaja de integraci√≥n.

R436. ISMS.online, 'ISO 42001: Ultimate Implementation Guide 2025', septiembre 2025. ISO 42001 Clause 8.2 (AI Supply Chain Risk Management): contratos y auditor√≠as de proveedores IA de terceros. Penetration testing, data poisoning simulation, adversarial input testing como parte del AIMS. Mapping a GDPR, NIST AI RMF, EU AI Act.

R437. Hicomply, 'ISO 42001 vs NIST AI RMF: How to Choose the Right Framework', noviembre 2025. ISO 42001: certifiable, structured blueprint para AIMS. NIST AI RMF: flexible playbook para risk management. Las organizaciones que buscan resiliencia, transparencia y regulatory readiness implementan ambos. No son rivales.

R438. Vanta, 'NIST AI RMF vs. ISO 42001: 5 differences to consider', octubre 2025. NIST AI RMF: empezar aqu√≠ (gratuito, no requiere compromiso de certificaci√≥n). Escalar a ISO 42001 a medida que madura el programa. Principios clave: accountability, fairness, explainability, data privacy, reliability.

R439. Lasso Security, 'ISO/IEC 42001: Features, Types and Best Practices', octubre 2025. Certificaci√≥n v√°lida 3 a√±os con auditor√≠as anuales. Requiere controles en: risk management, governance, transparency, bias mitigation, human oversight, lifecycle monitoring. ISO 42001 extends ISO 27001 (ISMS) espec√≠ficamente para IA.

<br>

Reporting al Board y Cultura de Gobernanza de IA:

R440. Help Net Security, 'Governance maturity defines enterprise AI confidence', diciembre 2025. Las organizaciones con gobernanza establecida muestran mayor alineaci√≥n Board-ejecutivos-seguridad. Mayor confianza para usar IA en SOC (detection, investigation, response). La gobernanza da exposici√≥n directa al comportamiento real de los sistemas de IA.

R441. Knostic, 'The 20 Biggest AI Governance Statistics and Trends of 2025'. An√°lisis de McKinsey State of AI 2025, Verizon 2025 DBIR, IBM Cost of a Data Breach 2025, Cisco Data Privacy Benchmark 2025, FBI IC3 2024. GenAI adoption ha outpaced governance maturity en todas las industrias.

R442. Harvard Law School Forum on Corporate Governance, 'Four Ways Boards Can Support the Effective Use of AI', mayo 2024. Solo 13% de S\&P 500 tiene directores con expertise en IA. La influencia del Board en AI governance es m√°s efectiva cuando incluye directores con background t√©cnico.

R443. ModelOp, '2025 AI Governance Benchmark Report'. Disconnected systems son el principal bloqueador de AI governance efectiva (58%). Gobernanza como habilitador: empresas con governance maduro despliegan AI 3x m√°s r√°pido que aquellas con governance ad-hoc.

<br>

S√≠ntesis y Referencias Cruzadas del Proyecto Completo:

R444. EU AI Act ‚Äî Hoja de Ruta Completa. Reglamento (UE) 2024/1689. Obligaciones aplicables agosto 2026 para sistemas de alto riesgo. Art. 9 (risk management system): ISO 42001 como evidencia de compliance. Art. 10 (data governance). Art. 13 (transparency). Art. 14 (human oversight).

R445. MITRE ATLAS octubre 2025. 15 t√°cticas + 66 t√©cnicas + 46 sub-t√©cnicas para amenazas contra sistemas de IA. Actualizaci√≥n octubre 2025: +14 nuevas t√©cnicas para AI Agents y GenAI (Zenity Labs). atlas.mitre.org.

R446. OWASP, 'OWASP Top 10 for LLM Applications 2025'. 5 nuevas categor√≠as vs. 2024: Excessive Agency (#6), System Prompt Leakage (#7), Vector/Embedding Weaknesses (#8), Misinformation (#9), Unbounded Consumption (#10). Prompt Injection #1 segundo a√±o consecutivo.

R447. Microsoft Purview Compliance Manager, 'Templates for AI Regulations 2025'. Templates disponibles: EU AI Act, GDPR, ISO 42001, ISO 23894, NIST 2 AI, Digital Operations Resilience Act. Mapping autom√°tico de controles implementados. Recomendaciones de acciones siguientes.

R448. Cloud Security Alliance, 'AI Security Maturity Model (AISMM)', 2025. Framework complementario de madurez de seguridad de IA. 5 niveles. Dominios: AI Asset Management, AI Risk Management, AI Operations Security, AI Privacy, AI Compliance.

R449. NIST AI RMF 1.0 + Generative AI Profile (NIST AI 600-1), 2024. Las 4 funciones core: GOVERN, MAP, MEASURE, MANAGE. El Generative AI Profile a√±ade gu√≠a espec√≠fica para LLMs: red teaming, guardrails, human-in-the-loop, output monitoring.

R450. Anthropic, OpenAI, Google DeepMind, Microsoft, Meta ‚Äî Responsible AI Frameworks 2025. Los 16 proveedores analizados en las Fases 1-8 del proyecto muestran convergencia hacia: AI safety research formal, red teaming pre-deployment, transparency reports anuales, gobernanza interna con AI Safety Committees. La brecha entre los l√≠deres de madurez √©tica (Anthropic, DeepMind) y los rezagados se mantiene significativa en dimensiones de explicabilidad y mecanismos de rendici√≥n de cuentas.

<br>

