# 4. Política "Human-in-the-Loop" (Verificación y Responsabilidad)

#### Encabezado Estándar para todas las Políticas

Estado: PROVISORIA (Versión Beta - Sujeta a revisión trimestral)

Vigencia Efectiva: 01 de Enero de 2026

Autoridad: CISO / Comité de Riesgos

Sanciones: El incumplimiento conllevará acciones disciplinarias según el Reglamento Interno y leyes laborales vigentes.

#### 4. Política "Human-in-the-Loop" (Verificación y Responsabilidad)

ID: POL-AI-04 | Enfoque: Mitigación de Alucinaciones

1. Propósito

Establecer la responsabilidad humana indelegable sobre cualquier resultado, producto, código o decisión generada total o parcialmente por sistemas de Inteligencia Artificial.

2\. Directrices Normativas

* Principio de Revisión: Ningún contenido generado por IA (código software, contratos legales, comunicaciones a clientes) puede ser puesto en producción o enviado sin una revisión, validación y edición humana verificable.
* Responsabilidad Final: El empleado que utiliza la herramienta de IA asume la responsabilidad legal y operativa completa por los errores, sesgos o infracciones de propiedad intelectual que la herramienta cometa. "Fue error de la IA" no se acepta como atenuante.

3\. Lo que debe dejar de ocurrir (Prohibiciones Explicitas)

* Auto-Commit: Configurar agentes de codificación para que envíen código (commit/push) a repositorios productivos sin Pull Request y revisión de pares humanos.
* Respuesta Automática Externa: Conectar IAs generativas directamente a buzones de correo de atención al cliente sin un paso intermedio de aprobación humana.
* Confianza Ciega: Tomar decisiones financieras o de contratación basándose únicamente en el resumen o scoring proporcionado por una IA.
