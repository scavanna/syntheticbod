---
icon: square-ring
---

# GLOSARIO LEGAL–TÉCNICO DE INTELIGENCIA ARTIFICIAL (Obligatorio para Contratos y Políticas)

<figure><img src="../.gitbook/assets/image.png" alt=""><figcaption></figcaption></figure>

<figure><img src="../.gitbook/assets/image (1).png" alt=""><figcaption></figcaption></figure>

<figure><img src="../.gitbook/assets/image (2).png" alt=""><figcaption></figcaption></figure>







## GLOSARIO LEGAL–TÉCNICO DE INTELIGENCIA ARTIFICIAL (Obligatorio para Contratos y Políticas)

***

### 1. Modelo

Sistema de inteligencia artificial, entrenado sobre datos mediante técnicas estadísticas o de machine learning, capaz de generar predicciones, clasificaciones, inferencias, recomendaciones o contenido sintético. Incluye su arquitectura, pesos (weights), hiperparámetros, embeddings, componentes de entrenamiento y versiones derivadas.

***

### 2. Modelo Fundacional (Foundation Model)

Tipo de Modelo entrenado sobre grandes volúmenes de datos heterogéneos, con capacidad generalista para múltiples tareas, que puede ser adaptado, refinado o especializado mediante Fine-Tuning o técnicas complementarias.

***

### 3. Modelo Generativo

Modelo capaz de producir contenido original en forma de texto, audio, imágenes, videos, código u otros formatos a partir de un Prompt o de datos estructurados.

***

### 4. Dataset

Conjunto de datos empleados para entrenar, evaluar o validar un Modelo. Puede incluir datos sintéticos, datos del Proveedor o datos del Cliente. Incluye metadatos, anotaciones y estructuras de organización.

***

### 5. Token

Unidad mínima de procesamiento utilizada por modelos de lenguaje. Puede corresponder a palabras, subpalabras, símbolos u otros fragmentos. El uso del Servicio puede medirse en tokens de entrada, salida o ambos.

***

### 6. Prompt

Instrucción, texto, comando, parámetro, archivo o información proporcionada al Modelo para solicitar una operación, inferencia o generación. El Prompt forma parte de los Datos del Cliente salvo pacto contrario.

***

### 7. Output o Salida

Resultado generado por el Modelo en respuesta a un Prompt o a otros Datos del Cliente. Puede ser texto, imagen, audio, código, estructura JSON, recomendación, clasificación u otro tipo de contenido.

***

### 8. Hallucination

Salida incorrecta, no verificable, no basada en hechos o carente de soporte en la información disponible. Incluye respuestas inventadas, referencias ficticias, inferencias no justificadas o contenido engañoso generado sin intención del usuario.

***

### 9. Fine-Tuning

Proceso de entrenamiento adicional, parcial o total, mediante el cual un Modelo preexistente se ajusta usando nuevos datos, típicamente específicos de un dominio o cliente, para mejorar desempeño en tareas concretas.

***

### 10. Fine-Tuning Personalizado

Fine-Tuning realizado utilizando Datos del Cliente o datasets exclusivos con el propósito de adaptar el Modelo a usos particulares.

***

### 11. Embedding

Representación matemática de datos en vectores de alta dimensión, generada por un Modelo, que permite búsquedas semánticas, comparaciones o razonamiento vectorial.

***

### 12. Evaluación de Riesgo Algorítmico

Proceso de análisis técnico y jurídico destinado a identificar riesgos asociados con el uso de modelos de IA, incluyendo bias, daños potenciales, uso indebido, fallas de seguridad, riesgos éticos y cumplimiento normativo.

***

### 13. Bias (Sesgo)

Desviación sistemática en el comportamiento o resultados del Modelo que produce resultados injustos, discriminatorios o desbalanceados para un grupo, atributo o categoría. Puede ser inherente al dataset, al proceso de entrenamiento o a la arquitectura del Modelo.

***

### 14. Mitigación de Bias

Conjunto de técnicas destinadas a reducir el sesgo en los Modelos o en las Salidas, incluyendo calibración, ajustes de datos, revisiones humanas, tests de equidad y filtros de seguridad.

***

### 15. Explicabilidad (Explainability)

Grado en que el funcionamiento, lógica, factores y elementos que influyen en una decisión algorítmica pueden ser entendidos, documentados o auditados por un humano.

***

### 16. Trazabilidad

Capacidad del sistema para rastrear, registrar o reconstruir el proceso de decisión o generación, incluyendo metadata de prompts, parámetros del modelo, logs y versiones de inferencia.

***

### 17. Log (Registro de Actividad)

Conjunto de datos que documenta la interacción con el Servicio, incluyendo prompts, outputs, tiempos, direcciones IP, usuarios, parámetros del Modelo y metadatos operativos. Puede contener datos personales o confidenciales.

***

### 18. Supervisión Humana (Human-in-the-Loop / Human-on-the-Loop / Human-out-of-the-Loop)

HITL: Un humano revisa, valida o aprueba cada Output antes de su uso final.\
HOTL: Un humano supervisa el sistema en tiempo real y puede intervenir.\
HOOTL: El sistema opera sin supervisión humana activa, sujeto a parámetros regulatorios.

***

### 19. Riesgo de IA (AI Risk)

Probabilidad de daño, directos o indirectos, causados por el uso de un Modelo, incluidos errores, bias, violaciones legales, impactos reputacionales, fallos de seguridad o resultados perjudiciales.

***

### 20. Caso de Uso de Alto Riesgo

Aplicación de un Modelo que pueda afectar derechos fundamentales, salud, seguridad física, decisiones financieras, procesos judiciales, laborales, biometría, operaciones críticas o gobernanza pública.

***

### 21. API (Application Programming Interface)

Interfaz que permite el acceso programático a los Servicios o Modelos, mediante solicitudes autenticadas, código o librerías.

***

### 22. Endpoint

Punto de acceso específico de la API al cual se envían solicitudes que ejecutan una función o invocan un Modelo.

***

### 23. Versión del Modelo

Conjunto identificado y estable del Modelo con parámetros definidos (v1.0, v1.1, GPT-X, LLaMA-X, etc.). Incluye políticas de soporte, deprecation y mantenimiento.

***

### 24. Model Version Locking

Garantía de que el Cliente podrá utilizar una versión específica del Modelo sin ser forzado a migrar a versiones posteriores.

***

### 25. Dataset Sintético

Data generada artificialmente por un Modelo o un proceso algorítmico, destinada a entrenamiento, evaluación o simulación.

***

### 26. Contenido Prohibido

Datos o instrucciones que no pueden ser utilizados por el Servicio (ej. pornografía infantil, datos biométricos sin consentimiento, identificadores sensibles, datos regulados sin autorización).

***

### 27. Filtro de Seguridad (Safety Layer)

Conjunto de controles técnicos diseñados para prevenir generación de Output riesgoso, ilegal o dañino.

***

### 28. Evaluación de Impacto Algorítmico (AIA / ALTAI / DPIA de IA)

Evaluación formal exigida por el AI Act u otras normas para identificar riesgos, mitigaciones y responsabilidades asociadas al uso de sistemas de IA.

***

### 29. Sandbox de IA

Entorno controlado donde se evalúan modelos, prompts, outputs y riesgos antes de su despliegue en producción.

***

### 30. Red Teaming de IA

Proceso estructurado de pruebas agresivas para identificar fallas de seguridad, jailbreaks, prompt injection, generación de contenido indebido o vulnerabilidades del Modelo.

***

### 31. Prompt Injection

Técnica mediante la cual un atacante manipula la interpretación del Modelo para ejecutar instrucciones no deseadas.

***

### 32. Jailbreak

Evasión de las restricciones, filtros de seguridad o límites del Modelo, mediante prompts maliciosos o técnicas adversariales.

***

### 33. Tasa de Error (Error Rate)

Medición cuantitativa del rendimiento del Modelo, según métricas específicas del caso de uso.

***

### 34. Evaluación de Performance

Medición de precisión, latencia, throughput, eficiencia, y consistencia de un Modelo o API.

***

### 35. Latencia

Tiempo que tarda el Servicio en procesar una solicitud desde la recepción del Prompt hasta la entrega del Output.

***

### 36. Throughput

Cantidad de solicitudes o tokens procesados por unidad de tiempo.

***

### 37. Contenido Derivado

Cualquier contenido generado a partir de las Salidas, transformado o utilizado por el Cliente para desarrollar nuevas obras, sistemas o productos.

***

### 38. Dominio de Aplicación

Sector o ámbito específico para el cual se utiliza un Modelo (legal, financiero, médico, educativo, industrial, etc.).

***

### 39. Controles de Mitigación

Medidas técnicas, organizativas o legales implementadas para reducir riesgos de IA.

***

### 40. Uso Permitido

Uso conforme a las licencias otorgadas por el Proveedor, las leyes aplicables y las restricciones contractuales.

***

<br>
